[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About us",
    "section": "",
    "text": "A great person indeed\n\n\n Role: Main contributor of the package and manuscript, slayer of dragon\n Title: PhD candidate\n Affiliation: Food and nutrition science division, department of Life science, Chalmers University of Technology\n Brief:\n Email:  yingxiao@chalmers.se"
  },
  {
    "objectID": "about.html#fa-person-rifle-titleshooter-fa-bullseye-titlearchery-yingxiao-yan",
    "href": "about.html#fa-person-rifle-titleshooter-fa-bullseye-titlearchery-yingxiao-yan",
    "title": "About us",
    "section": "",
    "text": "A great person indeed\n\n\n Role: Main contributor of the package and manuscript, slayer of dragon\n Title: PhD candidate\n Affiliation: Food and nutrition science division, department of Life science, Chalmers University of Technology\n Brief:\n Email:  yingxiao@chalmers.se"
  },
  {
    "objectID": "about.html#fa-chalkboard-user-titleacademic-fa-people-group-titlea-person-with-a-backpack-and-trekking-pol-carl-brunius",
    "href": "about.html#fa-chalkboard-user-titleacademic-fa-people-group-titlea-person-with-a-backpack-and-trekking-pol-carl-brunius",
    "title": "About us",
    "section": "\n  Carl Brunius",
    "text": "Carl Brunius\n\n\n\n\nKnivsta inhabitor\n\n\n Role: Supervisor of Yan\n Title: Associate professor\n Affiliation: Food and nutrition science division, department of Life science, Chalmers University of Technology\n Brief:\n Email:  carl.brunius@chalmers.se"
  },
  {
    "objectID": "about.html#fa-floppy-disk-titleacademic-anton-ribbenstedt",
    "href": "about.html#fa-floppy-disk-titleacademic-anton-ribbenstedt",
    "title": "About us",
    "section": "\n Anton Ribbenstedt",
    "text": "Anton Ribbenstedt\n\n\n\n\nhair length changes all the time\n\n\n Role: code helper and guider\n Title: Research engineer\n Affiliation: Chalmers Mass Spectrometry Infrastructure, Department of Life science, Chalmers university of Technology\n Brief:\n Email:  anton.ribbenstedt@chalmers.se"
  },
  {
    "objectID": "complex.html",
    "href": "complex.html",
    "title": "Tutorial(complex)- User Interface",
    "section": "",
    "text": "Before starting, please make sure you have installed the TriplotGUI package following Setup."
  },
  {
    "objectID": "complex.html#step-1-data-reduction-of-omics-data-and-auxiliary-data",
    "href": "complex.html#step-1-data-reduction-of-omics-data-and-auxiliary-data",
    "title": "Tutorial(complex)- User Interface",
    "section": "Step 1: Data reduction of Omics data and auxiliary data",
    "text": "Step 1: Data reduction of Omics data and auxiliary data\nFirst upload the Omics data and auxiliary data in step 1. Upon finish uploading the Omics data, a series buttons will also show up in case you need to to make some modification on the Omics or auxiliary data. Inspect the classes of variables briefly. You would see it looks okay for Omics data’s class but not auxiliary data. Some categorical variables should be in factor format rather than character. Therefore we change their classes.\n\n\n\n\n\n\n\n\n\nThen change the “Data analysis settings” and “Visualization settings” as figure. In this example, we will use WGCNA method to obtain the principal components and using auxiliary data to obtain more informative figures.\nWe could then examine the scree plot, score plot, loadings plot and biplot at step 1.\n\n\n You can then play around the visualization panel on the right side and view all the plots (score, loadings, biplot, screeplot)."
  },
  {
    "objectID": "complex.html#step-2-exposures-correlations-outcomes-associations",
    "href": "complex.html#step-2-exposures-correlations-outcomes-associations",
    "title": "Tutorial(complex)- User Interface",
    "section": "Step 2: Exposures’ correlations & Outcomes’ associations",
    "text": "Step 2: Exposures’ correlations & Outcomes’ associations\nThen upload exposures and covariate data in step 2A. By briefly inspecting variable classes, you could notice: - In the exposure data, \"HFI\"(Healthy Food Index) is a factor variable while \"BSDS\" (Baltic Sea Food Index) is a numeric variable. We may not need to change their classes at this point, but it is good to be aware of this to get a better understanding what happens in the downstream steps - A variable called \"X\" exists in the covariate data. This is because the covariate data is uploaded as a csv file and the observation number may automatically be generated as a new variable when the file is read in. Remove this variable since it is not an actual covariate.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that an rda file needs to be in the same directory as where you opened the TriplotGUI app.\n\n\nChange your “Data analysis settings” as the figure below.\n\n\n\n\n\n\nNote\n\n\n\n\nSelect One-hot-encoding in Categorical variables performs one-hot-encoding to transform categorical exposures variables (i.e. HFI) with n&gt;2 classes to n binary variables. If Use Original is specified in Categorical variables, then the HFI variable is forced to be a numeric variable. This is not recommended unless you are sure that the level itself reflects the numeric value.\nThe approaches for managing Missing values are inherited from the cor package for continuous exposures. Please check cor package for more information.\n\n\n\n\n\n\nYou could briefly see the correlation coefficients in “Visualizations” by clicking “Refresh plot”.\n\n\n\n\n\n\nThen in step 2B, upload outcome and covariate data By briefly inspecting variable classes, you could notice: - In the outcome data, \"BMI\" is a numeric variable; \"BMI_cat\" and \"T2D\" are factor variables. - A variable called \"X\" exists in the covariate data. This is because the covariate data is uploaded as a csv file and the observation number may automatically be generated as a new variable when the file is read in. Remove this variable since it is not an actual covariate.\n\n\n\n\n\n\n\n\n\nChange your “Data analysis settings” and “Visulization settings” as the figure below.\n\n\n\n\n\n\nNote\n\n\n\nSome clarification for using multinomial regression and pairing variables:\n\nWhen a pairing variable is not provided:\n\nNot performing multinomial regression means that one-hot-encoding will be performed to transform outcome’s categorical variables with n &gt; 2 classes to n binary variables. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables.\nPerforming multinomial regression means that multinomial regression will be performed on outcome’s categorical outcome variable with n &gt; 2 classes, which gives n-1 estimates. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables.\n\n\nWhen a pairing variable is provided:\n\nNot performing multinomial regression means that one-hot-encoding will be performed on outcome’s categorical variables with n &gt; 2 classes. And then conditional logistic regression will be performed on the binary variables and linear mixed model will be performed on continuous variables, using the pairing information.\nPerforming multinomial regression means that the pairing information will not be ignored and used (since the outcomes can have more than 2 classes), multinomial regression will be performed on outcome’s categorical variable, which gives n-1 estimates. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables. THIS IS THE CASE IN OUR EXAMPLE.\n\n\n\n\n\n\n\n\n\n\n\nYou could briefly see the risk estimate in “Visualizations” by clicking “Refresh plot”."
  },
  {
    "objectID": "complex.html#step-3-visualization-of-triplot",
    "href": "complex.html#step-3-visualization-of-triplot",
    "title": "Tutorial(complex)- User Interface",
    "section": "Step 3: Visualization of Triplot",
    "text": "Step 3: Visualization of Triplot\nIn step 3, by clicking “Refresh plot”, you can see and download the triplot that co-visualizing the three plots shown above. The left side panel gives you freedom of making adjustment to the plot. \nIn the triplot, blue circle points represent exposure correlations and the red square points represents outcome risk estimates with confidence interval. So what information can we get from this figure? Lets us list a few points:\n\nHaving a brief look, the generally healthy food (e.g. \"Fruits\", \"Vegetables\") is on the first dimension of the figure and the generally unhealthy food (e.g. \"Hamburger\", \"Sausage\", \"Margarine\") is on the third dimension of the figure. The numeric outcome \"BMI\", binary outcome \"T2D\", and one-hot-encoded categorical \"BMI_cat\" outcome is on the second and fourth dimension of the figure.\nExplanation on some variables in the plot:\n\n\n\"HFI\" stands for healthy food index. A higher \"HFI\" suggests healthier diet. \"HFI\" ranges from 0 to 6. You can see that there are HFI_0, HFI_1…HFI_6 in the figure and that is because \"HFI\" is used as a factor exposure variable in step 2 and is one-hot-encoded (´allowcategorical=F´) to the same number of binary variables as its number of levels. For example, HFI_6 is a binary variable where individuals with \"HFI 6\" (most healthy diet people) will be labeled as 1 and the rest of individuals will be labelled as 0. HFI_0 is a binary variable where individuals with \"HFI 6\" (most unhealthy diet people) will be labeled as 1 and the rest of individuals will be labelled as 0. HFI_1…HFI_5 has limited use since it only separates the group of people with certain \"HFI\" from to the rest, which is a mixture of healthier and less healthier diet people.\n\n\"BSDS\" stands for Baltic Sea Diet Score ranging. A higher \"BSDS\" suggests healthier diet. \"BSDS\" is used as a numeric variable ranging from 2 to 25 in this step.\n\nBMI_cat_obese, BMI_cat_overweight,BMI_cat_underweight are the odds ratio generated from the multinomial regression. Since \"BMI_cat\" is a categorical outcome and multinomial regression is performed in step 2 (multinomial=T), normal weight is uses as a reference and odds ratio of obese, overweight and underweight is produced. (Note that the first level of the factor variable is set as the default reference, in this case it is normal.\n\n\nAdjusting for \"Age\", \"Gender\", \"Smoking\", \"Education\" and \"FastingGlucose\", component from the first cluster (on x-axis) correlates positively with generally healthy food (e.g. \"fruits\", \"vegatables\") and food index (e.g. \"BSDS\") and negatively with unhealthy food (e.g. \"Hamburger\", \"pizza\"). It also reversely associated with \"T2D\" and \"BMI\". From the result from \"BMI_cat\", this components also reversely associated with being obese.\nComponent from the second cluster (on y-axis) associated positively with generally healthy food (e.g. \"fruits\", \"vegatables\") and food index (e.g. \"BSDS\") and negatively with unhealthy food (e.g. \"Hamburger\", \"pizza\"). However, the component correlates also positively with \"T2D\",\"BMI\", obese, overweight and negatively associated with underweight.\nBased on what we summarized above, the two components may be associated with a overall healthy eating pattern. And in such pattern, the first component is associated more with the beneficial effect on health and the second component represents the adverse health effect that may be caused by this pattern.\n\nThere are many things you could explore further in the following mediation analysis. To narrow down our focus and clearly show our examples, we select \"BSDS\" (Baltic Sea Diet Score) and \"Hamburger\" as our exposures, \"BMI\" and \"T2D\" as outcome to enter our next step."
  },
  {
    "objectID": "complex.html#step-4-mediation-analysis-and-visualization",
    "href": "complex.html#step-4-mediation-analysis-and-visualization",
    "title": "Tutorial(complex)- User Interface",
    "section": "Step 4: Mediation analysis and visualization",
    "text": "Step 4: Mediation analysis and visualization\nThis time, we perform the mediation analysis using the conterfactual/potential outcome method (the ´mediation´ package) on the our exposures (i.e. \"BSDS\", \"Hamburger\"), mediators (i.e. the first PC of the first 2 clusters) and outcome (i.e. \"T2D\", \"BMI\") of interest, adjusting for \"Age\", \"Gender\", \"Smoking\", \"Education\" and \"FastingGlucose\" for both exposure-mediator and mediator-outcome relationship.\n\n\n\n\n\n\nNote\n\n\n\nIn the counterfactual mediation analysis, you need to specify contrast values of treatment and controls for each exposure. In brief, the algorithm will compare the scenarios with these 2 exposure values/levels. For my detailed explanation please refer to this paper of the mediation R package.\nIf an exposure variable is continuous (numeric variable), it is recommended that the 2 exposure values is chosen between the range of the exposure variable. If an exposure variable is categorical (factor variable), the 2 exposure levels should be chosen from the levels of the exposure variable.\n\n\n\n\nUse the following settings for your data analysis. Mediation analysis is then performed using the counterfactual method on the our selected exposures, mediators and our selected outcomes, adjusting for covariates for both exposure-mediator and mediator-outcome relationship.\n\n\n\n\n\n\nNote\n\n\n\n\nNote that you need to click Do mediation to start running the mediation analysis.\n\n\n\n\n\n\n\n\nYou could then play around in the “Visualization settings” too see how you want to visualize your plot.\n\n\n\nYou could first only show the proportion mediated(PM) and adjust the limits to make the points more visible.\n\n\n\n\n\nIn the figure, we could see the direction and magnitude of proportion mediated for the 2 mediators, all the exposures and outcomes. Note that in the figure we have observed significant proportion mediated for BSDS-component 1-BMI and BSDS-component 2-BMI mediations\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nNote that some confidence intervals are automatically removed form the figure if they are not within the limit.\nNote that for some mediations, direct effect and indirect effects are in the opposite direction, implying possibly proportion mediated&gt;1, since total effect could smaller than indirect effect.\n\n\n\n\n\nYou then show the adjusted proportion mediated (APM) and adding the layers of correlation and risk estimates\n\n\n\n\n\n\n\nBy observing this figure, we could see the direction and magnitude of adjusted proportion mediated for the 2 mediators, all the exposures and outcomes. The position of the points is similar what we have seen for proportion mediated. Note that APM for BSDS as exposure and T2D as outcome is smaller than their PM. This is because the indirect and direct effect for this mediation is of similar size but in opposite direction. This leads to a smaller total effect and in turn larger PM, but APM will not be affected by the directionality of direct and indirect effect.\n\n\n\n\n\n\nNote\n\n\n\n\nNo confidence interval is shown for adjusted proportion mediated, as such value can not be directly calculated from the mediation analysis.\nNote that even direct effect and indirect effects are in the opposite direction, adjusted proportion mediated is always smaller than 1, since it uses the sum of the absolute value of indirect and direct effect as denominator. \\[APM=\\frac{IE}{|IE|+|DE|}\\cdot\\frac{|IE+DE|}{IE+DE}=\\frac{IE}{IE+DE}\\cdot\\frac{|IE+DE|}{|IE|+|DE|}=\\frac{IE}{IE+DE}\\cdot\\frac{|IE|+|DE|}{|IE+DE|}\\]\n\n\n\nIn step 4, you can also see the barplots showed direct, indirect and total effect for each exposure-mediator-outcome combination. It is a convenient tool to check the direction and magnitude of mediation estimates.\n\nBase on the barplot and the triplot with mediation, we have observed significant proportion mediated for BSDS-component1/2-BMI mediations. Further exploration on indirect, direct and total effect of the mediation analysis could be explored in the interface. We will not go into details here."
  },
  {
    "objectID": "complex.html#step-5-compare-correlations-associations-and-mediations",
    "href": "complex.html#step-5-compare-correlations-associations-and-mediations",
    "title": "Tutorial(complex)- User Interface",
    "section": "Step 5: Compare correlations, associations and mediations",
    "text": "Step 5: Compare correlations, associations and mediations\nUsers can then check the heatmaps of correlations, risk estimations and mediation results at step 5. By removing other PCs, exposures or outcomes in the “Visualization settings”, users may only show correlation, risk estimation and mediation results of their interest."
  },
  {
    "objectID": "complex.html#step-6-download-data",
    "href": "complex.html#step-6-download-data",
    "title": "Tutorial(complex)- User Interface",
    "section": "Step 6: Download data",
    "text": "Step 6: Download data\nRelevant data, intermediate results, can then be viewed and downloaded at step 6."
  },
  {
    "objectID": "complex_code.html",
    "href": "complex_code.html",
    "title": "Tutorial(complex) - Code",
    "section": "",
    "text": "Before starting,please make sure you have installed the TriplotGUI package following Setup.\nThe code of at this page can be downloaded here"
  },
  {
    "objectID": "complex_code.html#check-healthynordicdiet_2",
    "href": "complex_code.html#check-healthynordicdiet_2",
    "title": "Tutorial(complex) - Code",
    "section": "\n3.1 Check HealthyNordicDiet_2",
    "text": "3.1 Check HealthyNordicDiet_2\nCheck HealthyNordicDiet_2 as a list:\n\nCodeclass(HealthyNordicDiet_2)\n\n[1] \"list\"\n\nCodenames(HealthyNordicDiet_2)\n\n[1] \"ClinData\"       \"MetaboliteData\" \"FoodData\""
  },
  {
    "objectID": "complex_code.html#check-datasets",
    "href": "complex_code.html#check-datasets",
    "title": "Tutorial(complex) - Code",
    "section": "\n3.2 Check datasets",
    "text": "3.2 Check datasets\nCheck the names of variables in each data:\n\nCodecolnames(HealthyNordicDiet_2$ClinData)  \n\n [1] \"ID\"                    \"T2D\"                   \"PairedInfo\"           \n [4] \"Energy\"                \"Gender\"                \"Age\"                  \n [7] \"BMI\"                   \"Smoking\"               \"PhysicalActivityIndex\"\n[10] \"Education\"             \"FastingGlucose\"       \n\nCodecolnames(HealthyNordicDiet_2$MetaboliteData)\n\n [1] \"Pipecolic.acid.betaine\"         \"lysoPC.18.0.\"                  \n [3] \"HP143.1179.1.55\"                \"lysoPE.22.6.\"                  \n [5] \"HN151.0065.4.97\"                \"RP225.1482.9.15\"               \n [7] \"X3.4.5.Trimethoxycinnamic.acid\" \"DHA\"                           \n [9] \"RP383.1671.10.53\"               \"gama.tocopherol\"               \n[11] \"RP431.3516.11.96\"               \"RP490.3516.8.99\"               \n[13] \"lysoPC.22.6.\"                   \"Steroid.glucuronide\"           \n[15] \"RP684.5545.13.41\"               \"RP197.0926.3.17\"               \n[17] \"RP303.6468.9.98\"                \"RP816.5684.12.52\"              \n[19] \"RP827.5356.11.88\"               \"RP826.5442.12.17\"              \n[21] \"RN201.1498.8.23\"                \"RN203.0022.3.00\"               \n[23] \"EPA\"                            \"PC.18.2.15.0.\"                 \n[25] \"RN814.5610.12.14\"               \"RN153.0190.3.5\"                \n[27] \"RN427.1641.10.59\"               \"RN457.1742.10.50\"              \n[29] \"RN830.5845.12.46\"               \"RN446.1541.10.59\"              \n[31] \"RN472.1596.10.53\"              \n\nCodecolnames(HealthyNordicDiet_2$FoodData)\n\n [1] \"HFI\"           \"BSDS\"          \"Wholegrains\"   \"Sausage\"      \n [5] \"Pizza\"         \"Refined.bread\" \"Fruits\"        \"Liquor\"       \n [9] \"Wine\"          \"Hamburger\"     \"Poultry\"       \"Fish\"         \n[13] \"Margarine\"     \"Cabbage\"       \"Carrot\"        \"low_fat_Dairy\"\n[17] \"Vegetables\""
  },
  {
    "objectID": "complex_code.html#check-variables-class",
    "href": "complex_code.html#check-variables-class",
    "title": "Tutorial(complex) - Code",
    "section": "\n3.3 Check variables’ class",
    "text": "3.3 Check variables’ class\nWe Transform the data to dataframe format and then use TriplotGUI’s checkdata() function in to examine the class of variables.\n\nCodeClinData&lt;-as.data.frame(HealthyNordicDiet_2$ClinData)\nMetaboliteData&lt;-as.data.frame(HealthyNordicDiet_2$MetaboliteData)\nFoodData&lt;-as.data.frame(HealthyNordicDiet_2$FoodData)\n\nClinData_check&lt;-checkdata(ClinData)\nMetaboliteData_check&lt;-checkdata(MetaboliteData)\nFoodData_check&lt;-checkdata(FoodData)\n\n\n\nCodeClinData_check$class_sumamry_statistics\n\nNULL\n\nCodeMetaboliteData_check$class_sumamry_statistics\n\nNULL\n\nCodeFoodData_check$class_sumamry_statistics\n\nNULL\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that \"HFI\"(Healthy Food Index) is used as a factor variable and \"BSDS\"(the Baltic Sea Diet Score) is used as a numeric variable. You could use table(FoodData$HFI) and table(FoodData$BSDS) to check the difference."
  },
  {
    "objectID": "complex_code.html#check-sanities-for-variables",
    "href": "complex_code.html#check-sanities-for-variables",
    "title": "Tutorial(complex) - Code",
    "section": "\n3.4 Check sanities for variables",
    "text": "3.4 Check sanities for variables\nWhether each variable contains missing (NA) or abnormal values (e.g. NAN, Inf, blank value) can also be checked\n\nCodeClinData_check$everycolumn\n\n\n\n  \n\n\nCodeMetaboliteData_check$everycolumn\n\n\n\n  \n\n\nCodeFoodData_check$everycolumn\n\n\n\n  \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou shall only continue when the class of variables are correct and the missing or abnormal values in the variable are properly handled."
  },
  {
    "objectID": "complex_code.html#build-data-for-analysis",
    "href": "complex_code.html#build-data-for-analysis",
    "title": "Tutorial(complex) - Code",
    "section": "\n3.5 Build data for analysis",
    "text": "3.5 Build data for analysis\nWe see food data as our exposures and BMI and type 2 diabetes as outcomes. Note that BMI is a continuous variable. We can additionally construct BMI as a categorical outcome using the criteria below and see how this may differ the result.\n\nBMI &lt;= 18.5: Underweight\n18.5 &lt;BMI &lt;= 25: Normal\n25 &lt; BMI &lt;= 30: Overweight\n30 &lt; BMI: Obese\n\n\nCodeBMI&lt;-ClinData[,\"BMI\"]\nBMI_cat&lt;-vector(length=length(BMI))\nfor(i in 1:length(BMI)){\n  if(BMI[i]&lt;=18.5){\n    BMI_cat[i]&lt;-\"underweight\"\n  }else if (BMI[i]&gt;18.5&BMI[i]&lt;=25){\n    BMI_cat[i]&lt;-\"normal\"\n  }else if(BMI[i]&gt;25&BMI[i]&lt;=30){\n    BMI_cat[i]&lt;-\"overweight\"\n  }else{\n    BMI_cat[i]&lt;-\"obese\"\n  }\n}\nBMI_cat&lt;-as.factor(BMI_cat)\n\n\nWe want to explore the exposure-outcome relationships through the metabolomics data, using metabolites as assumed mediators. Gender, age, education, physical activity and smoking are used as potential confounders for exposure-mediator and mediator-outcome association. Auxiliary information regarding case-control pairs, fasting glucose level, education and physical activity are also provided.\n\nCodeexposure2&lt;-FoodData\nOmics2&lt;-MetaboliteData\noutcome2&lt;-cbind.data.frame(ClinData[,c(\"T2D\",\"BMI\")],BMI_cat)\ncovariates2&lt;-ClinData[,c(\"Gender\" ,\"Age\",\"Education\",\"PhysicalActivityIndex\",\"Smoking\" )]\nauxilary2&lt;-ClinData[,c(\"PairedInfo\",\"FastingGlucose\",\"Education\",\"PhysicalActivityIndex\", \"Energy\")]"
  },
  {
    "objectID": "complex_code.html#simple_link",
    "href": "complex_code.html#simple_link",
    "title": "Tutorial(complex) - Code",
    "section": "\n4.1 Step 1: Data reduction of omics data",
    "text": "4.1 Step 1: Data reduction of omics data\nUsing TriplotGUI package, first we perform dimension reduction, using weighted correlation network analysis (WGCNA) on metabolomics data.\n\nCode#* USing the complex settings\nreduced_Omics2&lt;-PCAorWGCNA_plots(dataframe=Omics2,\n                                 plottype=c(\"scree\",\"score\",\"loading\",\"scoreloading\"),\n                                 pc_type=\"principal\", \n# Users can choose freely to use principal() instead of prcomp() to perform PCA.The result should be very similar, but principal() allows more functionalites\n                                 first_PC=1,\n                                 second_PC=2,\n                                 option=\"WGCNA\",\n# In this example we use WGCNA to perform data reduction, therefore specifying `option=\"WGCNA\"`.\n                                 scale=T,\n                                 center=T,\n                                 eigen_loading=\"loading\",\n# If you want to show loading or scale it to eigevalues.\n                                 rotate=\"none\",\n# This argument is inherited from the principal() functions\n                                 size_variable=auxilary2$FastingGlucose,\n                                 size_variable_name=\"FastigGlucose\",\n                                 color_variable=auxilary2$Education,\n                                 color_variable_name=\"Education\",\n                                 shape_variable=auxilary2$PhysicalActivityIndex,\n                                 shape_variable_name=\"PhysicalActivityIndex\",\n# The size,shape,color variables are used to differentiate points on the score plot and biplot \n                                 loadings_name=T,\n# Show the names of loadings\n                                 loadings_cutpercent=0.2,\n# The loadings bigger than 20% of all the loadings will show up\n                                 minModuleSize=3\n# The mimimum number of variable in the clusters of WGCNA\n)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nIn WGCNA, Omics variables are separated into clusters. PCA are first performed on each cluster and the first principal component of each cluster will be used as the principal components of WGCNA.\nYou could try out the arguments of the PCAorWGCNA_plots() function and view the whole function here\n\nOne important argument in the PCAorWGCNA_plots() is minModuleSize, which defines the minimum number of variables in each cluster. If this number is specified as 2 high, for example, if you have 20 variables in total and you specify minModuleSize=15, you may only end up all the 20 variables as one cluster. In this case, only the first principal component of the cluster will be used and be shown on both axis of the generated triplots.\n\n\n\nYou can see scree plot, score plot, loadings plot and biplot at this stage.\n\nCodereduced_Omics2$scree_plot\n\nplot\n\n\n\n\n\nIn the scree plot, each cluster is named with different colors, and the column heights represents how much variance are explained by that cluster among the total variance. The darker color represents variance explained by the first principal component of each cluster. You may notice that in the grey cluster there is only darker color, not the lighter ones, this is because there is only one variable in that cluster - which will also be used as its first principal component. Even though we specified minModuleSize=2, sometimes there are variables left out by clustering and become a cluster of their own\nThe clusters are listed from left to right base on the number of variables in each cluster. The left side cluster has the most number of variables and right side cluster has the least number of variables.\n\nCodereduced_Omics2$score_plot\n\nplot\n\n\n\n\n\nAs the function specified, the scores are colored by education level, and the observations with different physical activity index are in different shape and people with different fasting glucose level are with different size.\n\nCodereduced_Omics2$loading_plot\n\nplot\n\n\n\n\n\nIn the loading plot, you can see that the loadings are all in the direction along the axis. This is because we use first principal components in each cluster. We cannot have the position of a loading in the direction of another axis since the another axis represents a different principal component analysis.\n\nCodereduced_Omics2$scoreloading_plot\n\nplot\n\n\n\n\n\nThe biplot with both score and loading looks a bit messy since there are so many things on the plot.\nWe then build a TPObject, which is used for saving information and pass them through steps in TriplotGUI.\n\nCodescores=reduced_Omics2$object$scores\nloadings&lt;-reduced_Omics2$object$loadings\nvariance&lt;- reduced_Omics2$object$variance\nTPObject1&lt;-makeTPO(scores=scores,\n                   loadings=loadings,\n                   variance=variance)\n\n\nMaking TriPlotObject (TPO)\n--------------------------\n\nScore matrix has 1000 observations and 5 components.\n\nTPO has 0 attached correlations.\nTPO has 0 attached risks."
  },
  {
    "objectID": "complex_code.html#step-2-exposures-correlations-outcomes-associations",
    "href": "complex_code.html#step-2-exposures-correlations-outcomes-associations",
    "title": "Tutorial(complex) - Code",
    "section": "\n4.2 Step 2: Exposures’ correlations & Outcomes’ associations",
    "text": "4.2 Step 2: Exposures’ correlations & Outcomes’ associations\nThe correlations between principal component (PC) scores and food items were calculated using Pearson correlations, adjusting for confounders. The associations between PC scores and risk markers were investigated using linear regression.\nCorrelation matrix of correlation coefficients and p values between the TPO scores saved in the TPObject and the dietary variables in the data is generated, using a pair-wise Pearson correlations, adjusting for confounders.\n\nCodeCorrelations_object&lt;-makeCorr(TPObject=TPObject1,\n                              corrData=exposure2,\n                              use='pairwise', \n                              # use inherit from cor() function \n                              method='pearson',\n                              # method inherit from cor() function \n                              allowcategorical=F,\n                              # one-hot-encoding on categorical exposures\n                              partial=T,\n                              # perform confonder adjustment\n                              confounder=covariates2)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nallowcategorical=F performs one-hot-encoding to transform categorical exposures variables with n&gt;2 classes to n binary variables. You can use Correlations_object$cor_estimate to check that each HFI level is separated in to a binary variable and the correlation coefficients between PCs and the binary variables were calculated. If allowcategorical=T is specified, then the HFI variable is forced as numeric variables. This is not recommended unless you are sure that the level itself reflects the numeric value.\npartial=T specifies that the confounders will be adjusted.\n\n\n\nThe result of correlations are then added into the TPObject.\n\nCodeTPObject2&lt;-addCorr(TPObject=TPObject1,\n                   Corr=Correlations_object$cor_estimate,\n                   Corr_p=Correlations_object$cor_pvalue)\n\n\nAdding correlation to TPO\n-------------------------\nPlease ensure same number of components in TPO and correlation matrix\n\nTPO has 23 attached correlations.\nTPO has 0 attached risks.\n\n\nMatrices of risk estimates and p values between the TPO scores saved in the TPObject and the outcome variables are generated, adjusting for confounders.\n\nCodeRisks_object&lt;-coefficient_get(TPObject=TPObject2,\n                              outcome=outcome2,\n                              confounder=covariates2,\n                              partial=T,\n                              # performs confounder adjustment\n                              multinomial=T,\n                              # multinomial regression is used\n                              pair=auxilary2$PairedInfo,\n                              # use the pairing information of case and control\n                              CI=0.95\n                              # confidence interval\n                              )\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\npartial=T specifies that the confounders will be adjusted.\nWhen pair information is not provided:\n\n\nmultinomial=F means that one-hot-encoding will be performed to transform outcome’s categorical variables with n &gt; 2 classes to n binary variables. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables.\nIf specifying multinomial=T, multinomial regression will be performed on outcome’s categorical outcome variable with n &gt; 2 classes, which gives n-1 estimates. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables.\n\n\nWhen pair information for case - control pair is provided:\n\n\nmultinomial=F means that one-hot-encoding will be performed on outcome’s categorical variables with n &gt; 2 classes. And then conditional logistic regression will be performed on the binary variables and linear mixed model will be performed on continuous variables, using the pairing information.\nIf specifying multinomial=T, the pairing information will not be ignored and used (since the outcomes can have more than 2 classes), multinomial regression will be performed on outcome’s categorical variable, which gives n-1 estimates. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables.\n\n\n\n\n\nThe result of risk estimates are then added into the TPObject.\n\nCodeTPObject3&lt;-addRisk(TPObject=TPObject2,\n                   Risk=Risks_object)\n\n\nAdding risk to TPO\n------------------\nPlease add risks one by one with component in rows and estimates, se:s and (optionally) p-values in columns\nPlease ensure same number of components in TPO and risk matrix\n\nTPO has 23 attached correlations.\nTPO has 5 attached risks."
  },
  {
    "objectID": "complex_code.html#step-3-visualization-of-triplot",
    "href": "complex_code.html#step-3-visualization-of-triplot",
    "title": "Tutorial(complex) - Code",
    "section": "\n4.3 Step 3: Visualization of Triplot",
    "text": "4.3 Step 3: Visualization of Triplot\nThen we can generate Triplot using the TPObject: Note that Triplot can be generated from any TPObject. You can try out different argument in the TriplotGUI() function. The function is a wrapper of PCA_TriplotGUI() and WGCNA_TriplotGUI(). You can view the functions respectively here: TriplotGUI() PCA_TriplotGUI() WGCNA_TriplotGUI()\n\nCodeTriplot_object3&lt;-TriplotGUI(TPObject3,\n                            first_PC=1,   ## The first PC to map\n                            second_PC=2,   ## The first PC to map\n                            plotLoads=TRUE,   \n                            ##Whether to plot loadings (TRUE; default) or suppress them (FALSE)\n                            plotScores=FALSE,   \n                            ##Whether to plot scores (TRUE) or suppress them (FALSE; default)\n                            plotCorr=TRUE,   \n                            ##Whether to plot correlations (TRUE; default) or suppress them (FALSE)\n                            plotRisk=TRUE,      \n                            ##Whether to plot risk estimates (TRUE; default) or suppress them (FALSE)\n                            ###############################################\n                            ##For loadings\n                            loadLabels=TRUE,   \n                            ###Whether to plot variable loading labels (TRUE; default) or not (FALSE)\n                            loadArrowLength=0.02,   \n                            ###Length of arrow tip , set it as 0 if you want to remove it\n                            loadCut=0,    \n                            ###lower limit Loadings below the cut are plotted in light grey and without label\n                            loadLim=NULL,   \n                            ##higher limit,Plot range for loadings\n                            ###############################################\n                            ##For correlations\n                            colCorr=\"blue\",   \n                            ##Color vector for correlations\n                            pchCorr=16,   \n                            ##Plotting character for correlations\n                            whichCorr=NULL,  \n                            ##Which correlations to plot (vector of numbers)\n                            corLim=NULL,     \n                            ##Plot range for correlations\n                            corrLabels = T,\n                            ###############################################\n                            ##For risks\n                            colRisk=\"red\",    \n                            ##Color vector for risk estimates\n                            pchRisk=15,    \n                            ##Plotting character for risk estimates\n                            whichRisk=NULL,  \n                            ##Which risk estimates to plot (vector of numbers)\n                            riskLim=NULL,            \n                            ##Plot range for risks\n                            riskWhisker_percentage=0.1,  \n                            ## whisker length is how many percentage of confidence interval\n                            riskLabels = T,\n                            size=3,\n                            # the size of points ont he plot\n                            riskOR=T\n                            # plot the risk estimates as odds ratio\n                            )\n\n\nWe then plot the triplot\n\nCodeTriplot_object3$triplot\n\nplot\n\n\n\n\n\nIn the triplot, blue circle points represent exposure correlations and the red square points represents outcome risk estimates with confidence interval. So what information can we get from this figure? Lets us list a few points:\n\nHaving a brief look, the generally healthy food (e.g. \"Fruits\", \"Vegetables\") is on the first dimension of the figure and the generally unhealthy food (e.g. \"Hamburger\", \"Sausage\", \"Margarine\") is on the third dimension of the figure. The numeric outcome \"BMI\", binary outcome \"T2D\", and one-hot-encoded categorical \"BMI_cat\" outcome is on the second and fourth dimension of the figure.\nExplanation on some variables in the plot:\n\n\n\"HFI\" stands for healthy food index. A higher \"HFI\" suggests healthier diet. \"HFI\" ranges from 0 to 6. You can see that there are HFI_0, HFI_1…HFI_6 in the figure and that is because \"HFI\" is used as a factor exposure variable in step 2 and is one-hot-encoded (allowcategorical=F) to the same number of binary variables as its number of levels. For example, HFI_6 is a binary variable where individuals with \"HFI\" as 6 (most healthy diet people) will be labeled as 1 and the rest of individuals will be labelled as 0. HFI_0 is a binary variable where individuals with \"HFI\" as 0 (most unhealthy diet people) will be labeled as 1 and the rest of individuals will be labelled as 0. HFI_1…HFI_5 has limited use since it only separates the group of people with certain \"HFI\" value from to the rest, which is a mixture of healthier and less healthier diet people.\n\n\"BSDS\" stands for Baltic Sea Diet Score ranging. A higher \"BSDS\" suggests healthier diet. \"BSDS\" is used as a numeric variable ranging from 2 to 25 in this step.\n\nBMI_cat_obese, BMI_cat_overweight,BMI_cat_underweight are the odds ratio generated from the multinomial regression. Since \"BMI_cat\" is a categorical outcome and multinomial regression is performed in step 2 (multinomial=T), normal weight is uses as a reference and odds ratio of obese, overweight and underweight is produced. (Note that the first level of the factor variable is set as the default reference, in this case it is normal).\n\n\nAdjusting for \"Age\", \"Gender\", \"Smoking\", \"Education\" and \"FastingGlucose\", component from the first cluster (on x-axis) correlates positively with generally healthy food (e.g. \"fruits\", \"vegatables\") and food index (e.g. \"BSDS\") and negatively with unhealthy food (e.g. \"Hamburger\", \"pizza\"). It also reversely associated with \"T2D\" and \"BMI\". From the result from \"BMI_cat\", this components also reversely associated with being obese.\nComponent from the second cluster (on y-axis) associated positively with generally healthy food (e.g. \"fruits\", \"vegatables\") and food index (e.g. \"BSDS\") and negatively with unhealthy food (e.g. \"Hamburger\", \"pizza\"). However, the component correlates also positively with \"T2D\",\"BMI\", obese, overweight and negatively associated with underweight.\nBased on what we summarized above, the two components may be associated with a overall healthy eating pattern. And in such pattern, the first component is associated more with the beneficial effect on health and the second component represents the adverse health effect that may be caused by this pattern.\n\nThere are many things you could explore further in the following mediation analysis. To narrow down our focus and clearly show our examples, we select \"BSDS\" (Baltic Sea Diet Score) and \"Hamburger\" as our exposures, \"BMI\" and \"T2D\" as outcome to enter our next step."
  },
  {
    "objectID": "complex_code.html#step-4-mediation-analysis-and-visualization",
    "href": "complex_code.html#step-4-mediation-analysis-and-visualization",
    "title": "Tutorial(complex) - Code",
    "section": "\n4.4 Step 4: Mediation analysis and visualization",
    "text": "4.4 Step 4: Mediation analysis and visualization\nThis time, we perform the mediation analysis using the conterfactual/potential outcome method (the ´mediation´ package) on the our exposures (i.e. \"BSDS\", \"Hamburger\"), mediators (i.e. the first PC of the first 2 clusters) and outcome (i.e. \"T2D\", \"BMI\") of interest, adjusting for \"Age\", \"Gender\", \"Smoking\", \"Education\" and \"FastingGlucose\" for both exposure-mediator and mediator-outcome relationship.\n\n\n\n\n\n\nNote\n\n\n\nIn the counterfactual mediation analysis, you need to specify contrast values of treatment and controls for each exposure. In brief, the algorithm will compare the scenarios with these 2 exposure values/levels. For my detailed explanation please refer to this paper of the mediation R package.\nIf an exposure variable is continuous (numeric variable), it is recommended that the 2 exposure values is chosen between the range of the exposure variable. If an exposure variable is categorical (factor variable), the 2 exposure levels should be chosen from the levels of the exposure variable.\n\n\n\nCodemediation_object3&lt;-\n  get_mediation_counterfactual (mediator=TPObject3$scores[,c(1:2),drop=F], \n                             # Specfiying at least 2 components so that there can be a 2-dimensional plot\n                             exposure=exposure2[,c(\"Hamburger\",\"BSDS\"),drop=F],\n                             outcome=outcome2[,c(\"BMI\",\"T2D\"),drop=F],\n                             exposure_treatment = c(25,19),\n                             exposure_control = c(2,0),\n                             confounder_ME=covariates2,\n                             confounder_OE=covariates2)\n\n\nLook at the barplot to have a more direct view on direct, indirect and total effects for each combination of exposure, mediator(princial component) and outcome.\n\nCodemediation_plot_object3&lt;-plot_mediation(mediation_object3,\n                                       cex=2\n                                       # size of the text\n                                       )\n\n\n\nCodemediation_plot_object3\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe barplot showed direct, indirect and total effect for each exposure-mediator-outcome combination. It is a convenient tool to check the direction and magnitude of mediation estimates. Red color represents significant positive effect (p&lt;0.05); Blue color represents significant negative effect (p&lt;0.05). Grey represents insignificant effect. One star for p&lt;0.05; Two stars for p&lt;0.01; Three stars for p&lt;0.001;\n\n\nAdd the mediation result into the TPObject.\n\nCodeTPObject4&lt;-add_mediation(TPObject3, mediation_object3)\n\n\nAdding mediation to TPO\n-------------------------\nNote that the exposures, mediators and outcomes are selected and not necessarily reflect total number of variables\n\nTPO mediation has used 2 mediators, 2 exposures, 2 outcomes\nMediators are turquoise, blue \nExposures are Hamburger, BSDS \nOutcomes are BMI, T2D\n\n\nMake the triplot with mediation. We showed the aruguments you could use in the function here with default values.\n\nCodeTriplot_object4 &lt;-\n  mediation_triplot(\n    TPObject4,\n    which_show = c(\"APM\",\"PM\"),\n    ##Which mediation estimate to show\n    first_PC = 1,\n    ##The first PC to map\n    second_PC = 2,\n    ##The second PC to map\n    plotMed = TRUE,\n    ##Whether to plot mediation estimates (TRUE; default) or suppress them (FALSE)\n    plotCorr = TRUE,\n    ##Whether to plot correlations (TRUE; default) or suppress them (FALSE)\n    plotRisk = TRUE,\n    ##Whether to plot risk estimates (TRUE; default) or suppress them (FALSE)\n    ###############################################\n    ##For correlations\n    colCorr = \"blue\",\n    ##Color vector for correlations\n    pchCorr = 16,\n    ##Plotting character for correlations\n    corrLim = NULL,\n    ##Plot range for correlations\n    corrLabels = T,\n    ##Add labels on exposures\n    ###############################################\n    ##For risks\n    colRisk = \"red\",\n    ##Color vector for risk estimates\n    pchRisk = 15,\n    ##Plotting character for risk estimates\n    riskLim = NULL,\n    ##Plot range for risks\n    Whisker_percentage_risk = 0.1,\n    ##whisker length is how many percentage of confidence interval\n    riskLabels = T,\n    ##Add labels on outcomes\n    riskOR = T,\n    #plot the risk estimates as odds ratio\n    ###############################################\n    ##For mediations\n    colmed = \"darkgreen\",\n    ##Color vector for mediation estimates\n    pchmed = 17,\n    ##Plotting character for mediation estimates\n    medLim = NULL,\n    ##Plot range for mediations\n    Whisker_percentage_med= 0.1,\n    ##whisker length is how many percentage of confidence interval\n    medLabels = T,\n    ##Add labels on mediation estimates\n    #########################################\n    \n    size = 3\n    # the size of points ont he plot\n  )\n\n\nOnly showing the mediation estimates (indirect and total effect).\n\nCodeTriplot_object4$mediation_plot\n\nplot\n\n\n\n\n\nThe proportion mediated (PM) and adjusted proportion mediated(APM) is presented as triangle points on the mediation plot, this is because we specified that we only want to show them using which_show = c(\"PM\", \"APM\") in the mediation_triplot() function.\nThe plot is a bit messy, all the points are crowded together, you could specify which_show = c(\"PM\") and which_show = c(APM\") respectively and re-run the mediation_triplot() function to see proportion mediated and adjusted proportion mediated separately.\n\nCodeTriplot_object4 &lt;-\n  mediation_triplot(\n    TPObject4,\n    which_show = c(\"PM\")\n  )\n\n\n\nCodeTriplot_object4$mediation_plot\n\nplot\n\n\n\n\n\nWe could see four data points on the figure, which represents the eight combinations of exposures, mediators and outcomes.\n\nexposure=BSDS, mediator= component 1, outcome=BMI\nexposure=BSDS, mediator= component 2, outcome=BMI\nexposure=Hamburger, mediator= component 1, outcome=BMI\nexposure=Hamburger, mediator= component 2, outcome=BMI\nexposure=BSDS, mediator= component 1, outcome=T2D\nexposure=BSDS, mediator= component 2, outcome=T2D\nexposure=Hamburger, mediator= component 1, outcome=T2D\nexposure=Hamburger, mediator= component 2, outcome=T2D\n\nWe could view from the confidence intervals on the figure already that some PM is not significant. A huge confidence interval presented on the plot has pushed the triangle points to the origin. If we want to zoom in and see which dimensions the points are in in the visualization.\nWe therefore adjust the limit of the proportion mediated to zoom in on the points. \"medLim = 2.5\" means that the limit showing on the plot will be from -2.5 to 2.5.\n\nCodeTriplot_object4 &lt;-\n  mediation_triplot(\n    TPObject4,\n    which_show = c(\"PM\"),\n    medLim = 2.5\n  )\n\n\n\nCodeTriplot_object4$mediation_plot\n\nWarning: Removed 3 rows containing missing values (`geom_errorbarh()`).\n\n\nplot\n\n\n\n\n\nIn the figure, we could see the direction and magnitude of proportion mediated for the 2 mediators, all the exposures and outcomes. We also notice that the PM for BSDS-component 1-BMI and BSDS-component 2-BMI mediation is significant.\n\n\n\n\n\n\nNote\n\n\n\n\nNote that some confidence intervals are automatically removed from the figure if they are not within the limit.\nNote that for some mediations, direct effect and indirect effects are in the opposite direction, implying possibly proportion mediated(PM)&gt;1, since total effect could smaller than indirect effect.\n\n\n\nwe then further look at the adjusted proportion mediated (APM).\n\nCodeTriplot_object4 &lt;-\n  mediation_triplot(\n    TPObject4,\n    which_show = c(\"APM\")\n  )\n\n\n\nCodeTriplot_object4$mediation_plot\n\nplot\n\n\n\n\n\nBy observing this figure, we could see the direction and magnitude of adjusted proportion mediated for the 2 mediators, all the exposures and outcomes. The position of the points is similar what we have seen for proportion mediated. Note that APM for BSDS as exposure and T2D as outcome is smaller than their PM. This is because the indirect and direct effect for this mediation is of similar size but in opposite direction. This leads to a smaller total effect and in turn larger PM, but APM will not be affected by the directionality of direct and indirect effect.\n\n\n\n\n\n\nNote\n\n\n\n\nNo confidence interval is shown for adjusted proportion mediated, as such value can not be directly calculated from the mediation analysis.\nNote that even direct effect and indirect effects are in the opposite direction, adjusted proportion mediated is always smaller than 1, since it uses the sum of the absolute value of indirect and direct effect as denominator. \\[APM=\\frac{IE}{|IE|+|DE|}\\cdot\\frac{|IE+DE|}{IE+DE}=\\frac{IE}{IE+DE}\\cdot\\frac{|IE+DE|}{|IE|+|DE|}=\\frac{IE}{IE+DE}\\cdot\\frac{|IE|+|DE|}{|IE+DE|}\\]\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want, you could specify which_show = c(\"PM\", \"APM\", \"IE\",\"DE\",\"TE\") in the mediation_troplot() to show all the estimates (IE for indirect effect, DE for direct effect and TE for total effect). However, it is not recommended, since the plot will get even messier if you put estimates and proportion mediated on the same plot.\nIf you go to Tutorial(simple), you can view the plot when showing \"IE\" and \"TE\".\n\n\nPlotting the triplot with mediation,\n\nCodeTriplot_object4$final_plot\n\nplot\n\n\n\n\n\nBase on the barplot and the triplot with mediation, we have observed significant proportion mediated for BSDS-component1/2-BMI mediations. Further exploration on indirect, direct and total effect of the mediation analysis could be explored by playing around the which_show argument in the mediation_troplot() function. We will not go into details here."
  },
  {
    "objectID": "complex_code.html#step-5-compare-correlations-associations-and-mediations",
    "href": "complex_code.html#step-5-compare-correlations-associations-and-mediations",
    "title": "Tutorial(complex) - Code",
    "section": "\n4.5 Step 5: Compare correlations, associations and mediations",
    "text": "4.5 Step 5: Compare correlations, associations and mediations\nUsers can check the heatmaps of correlations, risk estimations and mediation results from the TPObject through the checkTPO_ggplot() function in TriplotGUI.\n\nCodecheckTPObject4&lt;-checkTPO_ggplot(TPObject4,\n                                which_med=c(\"IE\",\"DE\",\"TE\",\"PM\",\"APM\"),\n                                ## What type of mediation estimate or proportion mediated to show on the heatmap\n                                which_PC=c(\"turquoise\", \"blue\"),\n                                ## What meditor (principal component) you want to show\n                                which_corr=c(\"Hamburger\",\"BSDS\"),\n                                ## What exposure variable you want to show\n                                which_risk=c(\"T2D\",\"BMI\")\n                                ## What outcome variable you want to show\n                                )\n\n\nCorrelation coefficients and p values between PC scores and exposures:\n\nCodecheckTPObject4$corr_coefficients\n\nplot\n\n\n\n\n\nRisk estimates(beta coefficients) and p values between PC scores and outcomes:\n\nCodecheckTPObject4$risk_coefficients\n\nplot\n\n\n\n\n\nMediation estimates and p values for indirect effect(IE), direct effect(DE) and total effect(TE), proportion mediated(PM) and adjusted proportion mediated(APM): See Details for more details:\n\nCodecheckTPObject4$med_coefficients\n\nplot\n\n\n\n\n\nYou could also View the three plots aboved combinedly.\n\nCodecheckTPObject4$corr_risk_med_coefficients\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nOne star for p&lt;0.05; Two stars for p&lt;0.01; Three stars for p&lt;0.001.\nNote that in the plot of checkTPbject4$med_coefficients, only the selected exposures, mediators and outcomes that we use to do mediation on will show up. The rows in the heatmaps are mediators and the column represents exposure-outcome pairs. For each exposure_outcome pair, 5 result are shown: IE (indirect effect), DE (direct effect), TE (total effect), PM(Proportion Mediated) and APM(Adjusted Proportion Mediated). Please see Details section for more information. The “CF” before the names of exposures-outcome pairs means that this mediation is using the Counterfactual method."
  },
  {
    "objectID": "complex_code.html#step-6-download-data",
    "href": "complex_code.html#step-6-download-data",
    "title": "Tutorial(complex) - Code",
    "section": "\n4.6 Step 6: Download data",
    "text": "4.6 Step 6: Download data\nWe can save all your output, including data, results and visualization output through the save() function as an rda file.\n\nCodesave(exposure2,Omics2,outcome2,covariates2,auxilariy2,\n     reduced_Omics2,Correlations_object,Risks_objects,\n     mediation_object3,mediation_plot_object3,\n     TPObject1,TPObject2,TPObject3,TPObject4,\n     checkTPObject4,\n     \"Tutorial_complex_output.rda\")\n\n\n\nCode#don't run code, but show code\n3\n\n\n\nCode#run code, and show code, don't show output\n4\n\n\n\n\n[1] 2\n\n\n[1] 3\n\n\n\n\n\n\nCode#run code, and show code, and show output\n5\n\n[1] 5\n\nCodes&lt;-function(x){x+1}\ns(23)\n\n[1] 24"
  },
  {
    "objectID": "explnation.html",
    "href": "explnation.html",
    "title": "explanation",
    "section": "",
    "text": "Scss rule explain\nThe index main page\nCV page\n.embed-container iframe\n.embed-container:\nThis is a class selector targeting an HTML element with the class name embed-container. It is likely used as a container for embedding various types of content.\niframe: This is an HTML element selector targeting the iframe element.\nCombined: .embed-container iframe: This selector targets any iframe element that is a descendant (child, grandchild, etc.) of an element with the class embed-container.\nThe  element in HTML is used to embed external resources, such as images, audio, videos, or other multimedia content, into a web page. It provides a generic container that allows you to include various types of content within your HTML document.\n&lt;object data=\"example.pdf\" type=\"application/pdf\" width=\"500\" height=\"600\"&gt; Your browser does not support embedded PDF files. &lt;a href=\"example.pdf\"&gt;Download the PDF&lt;/a&gt; instead. &lt;/object&gt;\nThe &lt;iframe&gt; element in HTML (Inline Frame) is used to embed another HTML document within the current document. It allows you to display content from another source, such as a different webpage, in a specified rectangular area on your page. The content inside the &lt;iframe&gt; is essentially a separate document with its own HTML, CSS, and JavaScript.\n&lt;iframe src=\"https://www.example.com\" width=\"600\" height=\"400\" frameborder=\"0\" allowfullscreen&gt;&lt;/iframe&gt;\nThe &lt;embeded&gt;Used to embed external applications or plugins.\n&lt;embed src=\"example.swf\" type=\"application/x-shockwave-flash\" width=\"400\" height=\"300\"&gt;\n#toolbar=0 This fragment is typically used with PDFs to control the visibility of the PDF viewer’s toolbar. Setting it to 0 generally means hiding the toolbar. The toolbar in a PDF viewer often contains options for navigation, zooming, and other related actions.\nThe height: 0; CSS property is used to set the height of an element to zero pixels. When applied to an element, this property essentially makes the element invisible in terms of its vertical dimension. The content inside the element, if any, will still exist but will be collapsed or hidden.\nHere’s a common use case for height: 0; along with other properties:\nThe CSS property overflow: hidden; is used to control how content that overflows the content area of an element should be handled. When applied to an element, it hides any content that exceeds the specified dimensions of the element’s box.\n\n\n\n \n\n \n\n  \n    © 2024 Yingxiao Yan CC BY-SA 4.0   \n    TriplotGUI gitlab\n    View source of this site on GitLab"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TriplotGUI",
    "section": "",
    "text": "This page gives a brief explanation of what the items in the navigation bar mean.\n\n\nSetup\nThis section gives instructions on how to install the packages needed, load library and activate the user interface.\n\n\nIntroduction\nThis section explains why we develop the TriplotGUI package: The research background, previous work of triplot and our aim.\n\n\nDetails\nThis sections gives detailed manual in analysis and visualization settings of TriplotGUI. We will not focus on the produced visualization output and interpretation here. Such content will be covered by the Tutorial and use case session.\n\n\nTutorial(simple)\nThis section provides a simple example of how to use the TriplotGUI package. The users can either use code or the user interface to achieve the similar purpose. The code tutorial suits for users that is at beginner R level. The user interface tutorial suits for user that has limited epidemiology knowledge and limited experience in dealing with high dimensional data.\nThe dataset used is CAMP_2\n\n\nTutorial(complex)\nThis section provides a more complex example of how to use the TriplotGUI package. The users can either use code or the user interface to achieve the similar purpose. The code tutorial suits for users that is at intermediate or advanced R level. The user interface tutorial suits for user that has epidemiology knowledge and experience in dealing with high dimensional data.\nThe dataset used is HealthyNordicDiet_2.\n\n\nUse Case\nThis section shows a smoother example of how to use the interface to perform data analysis and interpretation, omiting the detailed explanation in the tutorial.\nThe dataset used is ExposomeChallenge.\n\n\nPaper\nThis sections covers relevant papers of our TriplotGUI package\n\n\nAbout us\nThis sections give brief introduction of the contributors to this package.\n\n\nContact us\nIf you have questions in the package, tutorial and this website, or would like to seek collaboration, please contact yingxiao@chalmers.se"
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "Install packages\nPlease run the following code to install the packages needed. This needs to be run in your R console.\n\nCode### I may need mix Omics and impute not sure\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(\"mixOmics\")\nBiocManager::install(\"impute\")\nBiocManager::install(\"preprocessCore\")\nBiocManager::install(\"GO.db\")\n\ninstall.packages(\"remotes\")\nremotes::install_gitlab(\"YingxiaoYan/TriplotGUI\")\n\n\nThings may pop up in your console and ask you for some choices, we provide some recommedations here. We are conservative in the choices to avoid any unforseen conflict and complications in packages.\n\n\nSometimes it pops up in your console to ask you which package you would like to update. We recommened you to chose 3.None\n\n\nSometimes it pops up in your console to ask Do you want to install from soutce packages which need compliation . We recommended you to chose no\n\n\nSometimes it pops up in your console to ask Update all/some/none?[a/s/n] . We recommended you to chose n\n\nLoad libraries\nRun the following code in your R console.\n\nCodelibrary(TriplotGUI)\n\n\nDownload the example data for user interface\nGo to my git repository. Click the download icon at the right side and download the Exampledata.rar. Unzip it and you will find the data that will be used as example in the tutorial.\nChange the maximize size of data file allowed\nThe default of our package has allows data of maximize size of 5 MB. To change that, you could specify the maximize file size you prefer using the code below. Run your code in the console. However, we do not recommend to use data with more than 5 MB in our tool. The bigger the dataset, the slower it will be. It might be beneficial for you to do some variable selection before putting the data in out tool.\n\nCodefilesize=100  ##MB\noptions(shiny.maxRequestSize=filesize*1024^2)\n\n\nActivate the user interface\nRun the following code in your R console.\n\nCodeTriplotGUI_shiny_tryout()"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Overview\n   Most observational epidemiology research studies associations between single exposure and outcome. Emerging exposure- and outcome-wide studies aim to more broadly identify potential risk factors and their health effects. Although omics technologies have permitted linking exposures to outcomes via molecular data, large-scale exploration of mediating mechanisms is frequently lacking. Likely because Omics data are often high dimensional and there is a lack of effective tools for direct interpretation of the complex relationships between multiple exposures, Omics and outcomes. We therefore developed the TriplotGUI tool to advance exposome-risk assessment and facilitate the visualization and interpretation of such complex associations via metabolic regulation.\nThe application adopted a highly reactive stepwise modular design, where one or two modules represents one of the 6 following steps and the change of input from an early step will feed into a later step.\n \n\n\nSteps\nStep1: Data reduction of omics data\nTransforms the Omics data into a number of components using principal component analysis (PCA) or weighted correlation network analysis (WGCNA).\nStep2A: Exposures’ correlations\nAssesses correlations between exposures and component scores from Step 1. Confounders can be adjusted.\nStep2B: Outcomes’ associations\nAssesses risk associations between outcomes and the component scores from Step 1. Confounders can be adjusted.\nStep3: Visualization of Triplot\nThe component scores and loadings, the correlation coefficients and the risk associations’ estimates as beta coefficients or odds ratio, are co-visualized as 3 different layers in one 2-dimensional plot.\nStep4A: Mediation analysis and visualization\nPerforms mediation analysis on the selected exposures and outcomes, using component scores as mediators. The mediation estimates (i.e. indirect and total effect) or the proportion mediated are then co-visualized with the correlation coefficients of the selected exposures and the risk associations’ estimates as beta coefficients or odds ratio of the selected outcomes, as 3 different layers in one 2-dimensional plot.\nStep4B: Visualization for single mediations\nA clear overview of the magnitude and direction of indirect, direct and total effect of each single mediation analysis can be visualized through bar plots.\nStep5: Compare correlations, associations and mediations\nThe correlations, associations, mediation estimates and proportion mediated as well as their significance levels can be visualized through heatmap.\nStep6: Download data\nThe intermediate data and the generated results can be viewed and downloaded. The object that saves all relevant information can be downloaded.\n We will give detailed explanations of statistical data analysis and visualization in each step in the workflow session."
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "Relevant papers",
    "section": "",
    "text": "Download main paper \n\n\n\n\nMain paper\n\n\n\nSchillemans T, Shi L, Liu X, Åkesson A, Landberg R, Brunius C. Visualization and Interpretation of Multivariate Associations with Disease Risk Markers and Disease Risk-The Triplot. Metabolites. 2019 Jul 6;9(7):133. doi: 10.3390/metabo9070133\n\n\n\n\n\n\nOther papers\n\nBodén S, Zheng R, Ribbenstedt A, Landberg R, Harlid S, Vidman L, Gunter MJ, Winkvist A, Johansson I, Van Guelpen B, Brunius C. Dietary patterns, untargeted metabolite profiles and their association with colorectal cancer risk. Sci Rep. 2024 Jan 26;14(1):2244. doi: 10.1038/s41598-023-50567-6\nSchillemans T, Yan Y, Ribbenstedt A, Donat-Vargas C, Lindh CH, Kiviranta H, Rantakokko P, Wolk A, Landberg R, Åkesson A, Brunius C. OMICs Signatures Linking Persistent Organic Pollutants to Cardiovascular Disease in the Swedish Mammography Cohort. Environ Sci Technol. 2024 Jan 16;58(2):1036-1047. doi: 10.1021/acs.est.3c06388.\nTitova OE, Brunius C, Warensjö Lemming E, Stattin K, Baron JA, Byberg L, Michaëlsson K, Larsson SC. Comprehensive analyses of circulating cardiometabolic proteins and objective measures of fat mass. Int J Obes (Lond). 2023 Nov;47(11):1043-1049. doi: 10.1038/s41366-023-01351-z"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Projects",
    "section": "",
    "text": "This page contains a brief overview of projects that I significantly shaped throughout the entire project life cycle. In academic terms, this mostly corresponds to first-author publications (single and shared). If you’re interested in a full list of projects I have been involved in, please check out my CV."
  },
  {
    "objectID": "project.html#cmpe",
    "href": "project.html#cmpe",
    "title": "Projects",
    "section": "\n1 Consistency Model Posterior Estimation",
    "text": "1 Consistency Model Posterior Estimation\n\nPreprint (arXiv)\nConsistency models for neural posterior estimation (CMPE) is a new free-form conditional sampler for scalable, fast, and amortized simulation-based inference with generative neural networks. CMPE combines the advantages of normalizing flows and flow matching methods into a single generative architecture: It essentially distills a continuous probability flow and enables rapid few-shot inference with an unconstrained architecture that can be tailored to the structure of the estimation problem."
  },
  {
    "objectID": "project.html#multinpe",
    "href": "project.html#multinpe",
    "title": "Projects",
    "section": "\n2 Deep Fusion for Multimodal Simulation-Based Inference",
    "text": "2 Deep Fusion for Multimodal Simulation-Based Inference\n\nPreprint (arXiv)\nWe present multimodal neural posterior estimation (MultiNPE), a method to integrate heterogeneous data from different sources in simulation-based inference with neural networks. Inspired by advances in attention-based deep fusion learning, it empowers researchers to analyze data from different domains and infer the parameters of complex mathematical models with increased accuracy and better performance under partially missing data."
  },
  {
    "objectID": "project.html#data-efficient-amortized-bayesian-inference-via-self-consistency-losses",
    "href": "project.html#data-efficient-amortized-bayesian-inference-via-self-consistency-losses",
    "title": "Projects",
    "section": "\n3 Data-Efficient Amortized Bayesian Inference via Self-Consistency Losses",
    "text": "3 Data-Efficient Amortized Bayesian Inference via Self-Consistency Losses\n\nShort Paper (NeurIPS UniReps 2023)\nWe propose a method to improve the efficiency and accuracy of amortized Bayesian inference by leveraging universal symmetries in the probabilistic joint model \\(p(\\theta,y)\\). In a nutshell, we invert Bayes’ theorem and estimate the marginal likelihood based on approximate representations of the joint model. Upon perfect approximation, the marginal likelihood is constant across all parameter values by definition. However, approximation error leads to undesirable variance in the marginal likelihood estimates across different parameter values. We formulate violations of this symmetry as a loss function to accelerate the learning dynamics of conditional neural density estimators."
  },
  {
    "objectID": "project.html#meta-uncertainty-BMC",
    "href": "project.html#meta-uncertainty-BMC",
    "title": "Projects",
    "section": "\n4 Meta-Uncertainty in Bayesian Model Comparison",
    "text": "4 Meta-Uncertainty in Bayesian Model Comparison\n\nPaper (AISTATS 2023) | Code | ’Project website | Poster | Presentation (15min)\nMeta-Uncertainty represents a fully probabilistic framework for quantifying the uncertainty over Bayesian posterior model probabilities (PMPs) using meta-models. Meta-models integrate simulated and observed data into a predictive distribution for new PMPs and help reduce overconfidence and estimate the PMPs in future replication studies."
  },
  {
    "objectID": "project.html#bayesflow-amortized-bayesian-workflows-with-neural-networks",
    "href": "project.html#bayesflow-amortized-bayesian-workflows-with-neural-networks",
    "title": "Projects",
    "section": "\n5 BayesFlow: Amortized Bayesian Workflows With Neural Networks",
    "text": "5 BayesFlow: Amortized Bayesian Workflows With Neural Networks\n\nSoftware Paper | Documentation | BayesFlow Forums (new!)\nBayesFlow is a Python library for simulation-based training of established neural network architectures for amortized data compression and inference. Amortized Bayesian inference, as implemented in BayesFlow, enables users to train custom neural networks on model simulations and re-use these networks for any subsequent application of the models. Since the trained networks can perform inference almost instantaneously, the upfront neural network training is quickly amortized."
  },
  {
    "objectID": "project.html#jana-jointly-amortized-neural-approximation-of-complex-bayesian-models",
    "href": "project.html#jana-jointly-amortized-neural-approximation-of-complex-bayesian-models",
    "title": "Projects",
    "section": "\n6 JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models",
    "text": "6 JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models\n\nPaper (UAI 2023) | Python library\nJANA is a new amortized solution for intractable likelihood functions and posterior densities in Bayesian modeling. It trains three networks to learn both an approximate posterior and a surrogate model for the likelihood, enabling amortized marginal likelihood and posterior predictive estimation."
  },
  {
    "objectID": "project.html#sbi-model-misspecification",
    "href": "project.html#sbi-model-misspecification",
    "title": "Projects",
    "section": "\n7 Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks",
    "text": "7 Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks\n\nPaper (GCPR 2023, Best Paper Honorable Mention) | Code | Poster Novel neural network based architectures enable amortized Bayesian inference in settings where the likelihood function is only implicitly defined by a simulation program. But how faithful is such inference when simulations represent reality somewhat inaccurately? This paper illustrates how imposing a probabilistic structure on the latent data summary space can help to detect potentially catastrophic domain shifts during inference.\n\nCode#don't run code, but show code\n3\n\n\n\nCode#run code, and show code, don't show output\n4\n\n\n\n\n[1] 2\n\n\n[1] 3\n\n\n\nCode#run code, and show code, and show output\n5\n\n[1] 5\n\nCodes&lt;-function(x){x+1}\ns(23)\n\n[1] 24\n\n\nFOR REFERENCE: Graduation Cap\n # stopped working 5/1/2023?"
  },
  {
    "objectID": "pub_ho.html",
    "href": "pub_ho.html",
    "title": "Publication & honor",
    "section": "",
    "text": "Luyan Wu, Wenhui Zeng, Liandong Feng, Yuxuan Hu, Yidan Sun, Yingxiao Yan, HongYuan Chen & Deju Ye. An activatable radiometric near-inflared fluorescent probe for hydrogen sulfide imaging in vivo. Science China Chemistry. 2020;63(5):741-750 Yan Y, Smith E, Melander O, Ottosson F. The association between plasma metabolites and future risk of all‐cause mortality. Journal of Internal Medicine. 2022;292(5):804-815.  Schillemans T, Yan Y, Ribbenstedt A, Donat-Vargas C, Lindh C, Kivirante H, Wolk A, et al.OMICs signatures linking persistent organic pollutants to cardiovascular disease in the Swedish Mammography Cohort [Submitted]"
  },
  {
    "objectID": "pub_ho.html#publications",
    "href": "pub_ho.html#publications",
    "title": "Publication & honor",
    "section": "",
    "text": "Luyan Wu, Wenhui Zeng, Liandong Feng, Yuxuan Hu, Yidan Sun, Yingxiao Yan, HongYuan Chen & Deju Ye. An activatable radiometric near-inflared fluorescent probe for hydrogen sulfide imaging in vivo. Science China Chemistry. 2020;63(5):741-750 Yan Y, Smith E, Melander O, Ottosson F. The association between plasma metabolites and future risk of all‐cause mortality. Journal of Internal Medicine. 2022;292(5):804-815.  Schillemans T, Yan Y, Ribbenstedt A, Donat-Vargas C, Lindh C, Kivirante H, Wolk A, et al.OMICs signatures linking persistent organic pollutants to cardiovascular disease in the Swedish Mammography Cohort [Submitted]"
  },
  {
    "objectID": "pub_ho.html#conference-and-awards",
    "href": "pub_ho.html#conference-and-awards",
    "title": "Publication & honor",
    "section": "\n2 Conference and awards",
    "text": "2 Conference and awards\n\n\nMetabolomics 2022, Valencia, Spain. - Speaker, with award\n\n\nSwedish Bioinformatics workshop 2022,Umeå, Sweden. - Speaker\n\n\nNordic rye forum 2022, Stockholm, Sweden - Speaker"
  },
  {
    "objectID": "pub_ho.html#key-competence",
    "href": "pub_ho.html#key-competence",
    "title": "Publication & honor",
    "section": "\n3 Key competence",
    "text": "3 Key competence\n\n\nR/shiny (data cleaning, manipulation, analysis, and visualization) - Expert\n\n\nBiostatistics and epidemiological research - Expert\n\n\nSPSS, Excel & Microsoft Office suite - Expert\n\n\npython - Intermediate"
  },
  {
    "objectID": "pub_ho.html#languages",
    "href": "pub_ho.html#languages",
    "title": "Publication & honor",
    "section": "\n4 Languages",
    "text": "4 Languages\n\n\nMandarin (Native speaker)\n\n\nEnglish (Native level)\n\n\nSwedish (Intermediate/B1 level, SAS certificated)"
  },
  {
    "objectID": "pub_ho.html#references",
    "href": "pub_ho.html#references",
    "title": "Publication & honor",
    "section": "\n5 References",
    "text": "5 References\nFilip Ottoson Postdoctoral Researcher – Lund University Email: filip.ottoson@med.lu.se Tel: +46739699000 Carl Brunius Associate Professor – Chalmers University of Technology Email: calbrunius@chalmers.se Tel:\n\n© 2023 Yingxiao Yan ★★★★★. All rights reserved"
  },
  {
    "objectID": "pub_ho.html#news",
    "href": "pub_ho.html#news",
    "title": "Publication & honor",
    "section": "\n6 News",
    "text": "6 News\n\nJanuary 23, 2024: I will be at Bayes on the Beach 2024 in February. I will give a talk about reliable amortized Bayesian inference with neural networks and co-lead a workshop on amortized Bayesian workflows.\nDecember 2023: We launched the BayesFlow Forums! The BayesFlow Forums provide a community for asking and answering questions about all aspects of BayesFlow and amortized Bayesian workflows in general. Hop over and join the discussion!\nOctober 11, 2023: In our recent preprint, we make simulation-based inference more data-efficient by leveraging self-consistency properties of the Bayesian joint model. You find the preprint on arXiv. Update: Published in the NeurIPS UniReps workshop.\nSeptember 22, 2023: Our paper “Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks” has been awarded the DAGM GCPR Honorable Mention at this year’s German Conference on Pattern Recognition. Huge thanks to my great co-authors!\nSeptember 6, 2023: Our paper “Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks” has been accepted with oral presentation at the German Conference for Pattern Recognition 2023. Learn more at the project website.\nJune 21, 2023: I will be at the ELLIS Doctoral Symposium 2023 in Helsinki from August 28 to September 1, 2023. Absolutely thrilled to meet other PhD students and researchers and talk about machine learning research in beautiful Helsinki!\nMay 9, 2023: Our paper “JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models” has been accepted to UAI 2023 (Uncertainty in AI). Check out the project page to find out more!\nMarch 29, 2023: I’ll be presenting our paper on Meta-Uncertainty in Bayesian Model Comparison at AISTATS 2023 from April 25-27 in Valencia, Spain. You find links to the paper and code on my Projects page or on the dedicated paper website. If you see me around at AISTATS, let’s chat!"
  },
  {
    "objectID": "pub_ho.html#featured-blog-posts",
    "href": "pub_ho.html#featured-blog-posts",
    "title": "Publication & honor",
    "section": "\n7 Featured Blog Posts",
    "text": "7 Featured Blog Posts\n\n\n\n\nCode#don't run code, but show code\n3\n\n\n\nCode#run code, and show code, don't show output\n4\n\n\n\n\n[1] 2\n\n\n\nCode#run code, and show code, and show output\n5\n\n[1] 5"
  },
  {
    "objectID": "simple.html",
    "href": "simple.html",
    "title": "Tutorial(simple) - User Interface",
    "section": "",
    "text": "Before starting, please make sure you have installed the TriplotGUI package following Setup."
  },
  {
    "objectID": "simple.html#step-1-data-reduction-of-omics-data",
    "href": "simple.html#step-1-data-reduction-of-omics-data",
    "title": "Tutorial(simple) - User Interface",
    "section": "Step 1: Data reduction of omics data",
    "text": "Step 1: Data reduction of omics data\n\n\nFirst upload the Omics data in step 1 and then examine the scree plot, score plot, loadings plot and biplot at step 1. \nUpon finish uploading the Omics data, a series buttons will also show up in case you need to to make some modification on the Omics data.\n\nYou can then play around the visualization panel on the right side and view all the plots (score, loadings, biplot, screeplot)."
  },
  {
    "objectID": "simple.html#step-2-exposures-correlations-outcomes-associations",
    "href": "simple.html#step-2-exposures-correlations-outcomes-associations",
    "title": "Tutorial(simple) - User Interface",
    "section": "Step 2: Exposures’ correlations & Outcomes’ associations",
    "text": "Step 2: Exposures’ correlations & Outcomes’ associations\nThen upload exposures, outcomes and covariates data in step 2.\n\nYou could briefly see the correlation coefficients and risk estimates at step 2 respectively in visualizations by clicking “Refresh plot”."
  },
  {
    "objectID": "simple.html#step-3-visualization-of-triplot",
    "href": "simple.html#step-3-visualization-of-triplot",
    "title": "Tutorial(simple) - User Interface",
    "section": "Step 3: Visualization of Triplot",
    "text": "Step 3: Visualization of Triplot\nIn step 3, by clicking “Refresh plot”, you can see and download the triplot that co-visualizing the three plots shown above. The left side panel gives you freedom of making adjustment to the plot. \nIn the triplot, PC1 reflected metabolites that were positively associated with BMI and also correlated with a high intake of meat and refined grains, adjusting for age and sex. This implies that the metabolite features that contributes most to PC1, are likely to provide useful information for a potential mechanism of how red meat and refrained grains intake may affect BMI."
  },
  {
    "objectID": "simple.html#step-4-mediation-analysis-and-visualization",
    "href": "simple.html#step-4-mediation-analysis-and-visualization",
    "title": "Tutorial(simple) - User Interface",
    "section": "Step 4: Mediation analysis and visualization",
    "text": "Step 4: Mediation analysis and visualization\n\n\n\n\n\n\nUse the following settings for your data analysis. Mediation analysis is then performed using the Baron-Kenny conventional “product” method on the our exposures (i.e. Refined grains, Red meat), mediator (i.e. PC1, PC2) and outcome (i.e. BMI) of interest, adjusting for age and sex for both exposure-mediator and mediator-outcome relationship.\n\n\n\n\n\n\nNote\n\n\n\n\nNote that you need to click Do mediation to start running the mediation analysis.\nIn the default setting, only proportion mediated is visualized. You could go to the “Visualization setting” to select Mediation estimate or proportion as Estimate to show the indirect effect or total effect triplot with mediation.\n\n\n\n\n\n\nIn step 4, you can also see the barplots showed direct, indirect and total effect for each exposure-mediator-outcome combination. It is a convenient tool to check the direction and magnitude of mediation estimates.\n\nBased on the barplot and the triplot with mediation, we observed a significant mediation effect through PC1 for Red_meat-BMI and refined_grain-BMI association. This further implies that the metabolite features that contributes to PC1 are likely to mediate the pathway from red meat and refined grain intake to BMI change."
  },
  {
    "objectID": "simple.html#step-5-compare-correlations-associations-and-mediations",
    "href": "simple.html#step-5-compare-correlations-associations-and-mediations",
    "title": "Tutorial(simple) - User Interface",
    "section": "Step 5: Compare correlations, associations and mediations",
    "text": "Step 5: Compare correlations, associations and mediations\nUsers can then check the heatmaps of correlations, risk estimations and mediation results at step 5. By removing other PCs in the “Visualization settings”, users may only show results relvant to PC1 and PC2."
  },
  {
    "objectID": "simple.html#step-6-download-data",
    "href": "simple.html#step-6-download-data",
    "title": "Tutorial(simple) - User Interface",
    "section": "Step 6: Download data",
    "text": "Step 6: Download data\nRelevant data, intermediate results, can then be viewed and downloaded at step 6."
  },
  {
    "objectID": "simple_code.html",
    "href": "simple_code.html",
    "title": "Tutorial(simple) - Code",
    "section": "",
    "text": "Before starting,please make sure you have installed the TriplotGUI package following Setup.\nThe code of at this page can be downloaded here"
  },
  {
    "objectID": "simple_code.html#check-camp_2",
    "href": "simple_code.html#check-camp_2",
    "title": "Tutorial(simple) - Code",
    "section": "\n3.1 Check CAMP_2",
    "text": "3.1 Check CAMP_2\nCheck CAMP_2 as a list:\n\nCodeclass(CAMP_2)\n\n[1] \"list\"\n\nCodenames(CAMP_2)\n\n[1] \"FoodData\"       \"MetaboliteData\" \"ClinData\""
  },
  {
    "objectID": "simple_code.html#check-datasets",
    "href": "simple_code.html#check-datasets",
    "title": "Tutorial(simple) - Code",
    "section": "\n3.2 Check datasets",
    "text": "3.2 Check datasets\nCheck the names of variables in each data:\n\nCodecolnames(CAMP_2$ClinData)\n\n [1] \"AGE\"               \"SEX\"               \"BMI\"              \n [4] \"triglycerides\"     \"total_cholesterol\" \"HDL\"              \n [7] \"LDL\"               \"GGT\"               \"ALT\"              \n[10] \"AST\"               \"creatinine\"        \"Urea_nitrogen\"    \n[13] \"Uric_acid\"         \"Fasting_glucose\"  \n\nCodecolnames(CAMP_2$MetaboliteData)\n\n [1] \"PC_P_20_0_22_6_\"                                                                \n [2] \"X1__3_4_Dihydroxyphenyl__7__4_hydroxy_3_methoxyphenyl__1_6_heptadiene_3_5_dione\"\n [3] \"Unknown_675.6485_9.35\"                                                          \n [4] \"Unknown_1066.9034_10.16\"                                                        \n [5] \"PC_42_8_\"                                                                       \n [6] \"Unknown_931.7610_9.68\"                                                          \n [7] \"TG_52_0_\"                                                                       \n [8] \"CE_22_4_\"                                                                       \n [9] \"Neutral_glycosphingolipids1023.67\"                                              \n[10] \"TG_58_10_\"                                                                      \n[11] \"Neutral_glycosphingolipids971.72\"                                               \n[12] \"Unknown_914.7433_10.06\"                                                         \n[13] \"Cucurbic_acid\"                                                                  \n[14] \"DG_16_0_18_2_\"                                                                  \n[15] \"Indoleacrylic_acid\"                                                             \n[16] \"PC_O_20_0_22_6_\"                                                                \n[17] \"Unknown_948.6589_8.51\"                                                          \n[18] \"Unknown_858.5318_5.49\"                                                          \n[19] \"O_propanoyl_carnitine\"                                                          \n[20] \"DG_38_5_\"                                                                       \n\nCodecolnames(CAMP_2$FoodData)\n\n [1] \"Refined_grains\" \"Coarse_grains\"  \"Red_meat\"       \"Poutry\"        \n [5] \"Seafood\"        \"Egg\"            \"Animal_organs\"  \"Vegetables\"    \n [9] \"Fruits\"         \"Potatos\"        \"Legumes\""
  },
  {
    "objectID": "simple_code.html#check-variables-class",
    "href": "simple_code.html#check-variables-class",
    "title": "Tutorial(simple) - Code",
    "section": "\n3.3 Check variables’ class",
    "text": "3.3 Check variables’ class\nWe then transform the data to dataframe format and then use TriplotGUI’s checkdata() function in to examine the classes of variables.\n\nCodeClinData&lt;-as.data.frame(CAMP_2$ClinData)\nMetaboliteData&lt;-as.data.frame(CAMP_2$MetaboliteData)\nFoodData&lt;-as.data.frame(CAMP_2$FoodData)\n\nClinData_check&lt;-checkdata(ClinData)\nMetaboliteData_check&lt;-checkdata(MetaboliteData)\nFoodData_check&lt;-checkdata(FoodData)\n\n\n\nCodeClinData_check$class_sumamry_statistics\n\n$check_class_vector\n              AGE               SEX               BMI     triglycerides \n        \"numeric\"          \"factor\"         \"numeric\"         \"numeric\" \ntotal_cholesterol               HDL               LDL               GGT \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n              ALT               AST        creatinine     Urea_nitrogen \n        \"numeric\"         \"numeric\"         \"numeric\"         \"numeric\" \n        Uric_acid   Fasting_glucose \n        \"numeric\"         \"numeric\" \n\n$check_class_table\ncheck_class_vector\n factor numeric \n      1      13 \n\nCodeMetaboliteData_check$class_sumamry_statistics$check_class_table\n\ncheck_class_vector\nnumeric \n     20 \n\nCodeFoodData_check$class_sumamry_statistics\n\n$check_class_vector\nRefined_grains  Coarse_grains       Red_meat         Poutry        Seafood \n     \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\" \n           Egg  Animal_organs     Vegetables         Fruits        Potatos \n     \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\" \n       Legumes \n     \"numeric\" \n\n$check_class_table\ncheck_class_vector\nnumeric \n     11"
  },
  {
    "objectID": "simple_code.html#check-sanities-for-variables",
    "href": "simple_code.html#check-sanities-for-variables",
    "title": "Tutorial(simple) - Code",
    "section": "\n3.4 Check sanities for variables",
    "text": "3.4 Check sanities for variables\nWhether each variable contains missing (NA) or abnormal values (e.g. NAN, negative values, Indefinite values, blank values) can also be checked.\nThe previous checkdata() function can also generate a table to summarize how many and how many percentage of observations contain NA, NAN, zero, negative, indefinite(inf),and blank values(” “) for each variable in each data frame.\n\nCodeClinData_check$everycolumn\n\n\n\n  \n\n\nCodeMetaboliteData_check$everycolumn\n\n\n\n  \n\n\nCodeFoodData_check$everycolumn\n\n\n\n  \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou shall only continue when the class of variables are correct and the missing or abnormal values in the variable are properly handled."
  },
  {
    "objectID": "simple_code.html#build-data-for-analysis",
    "href": "simple_code.html#build-data-for-analysis",
    "title": "Tutorial(simple) - Code",
    "section": "\n3.5 Build data for analysis",
    "text": "3.5 Build data for analysis\nWe see food data as our exposures and BMI, triglycerides, total_cholesterol, HDL and LDL as outcomes. We want to explore their relationships through the metabolomics data, using metabolites as assumed mediators. Sex and age are used as potential confounders for exposure-mediator and mediator-outcome association.\n\nCodeexposure1&lt;-FoodData\nOmics1&lt;-MetaboliteData\noutcome1&lt;-ClinData[,c(\"BMI\",\"triglycerides\",\"total_cholesterol\",\"HDL\",\"LDL\")]\ncovariates1&lt;-ClinData[,c(\"SEX\" ,\"AGE\")]"
  },
  {
    "objectID": "simple_code.html#simple_link",
    "href": "simple_code.html#simple_link",
    "title": "Tutorial(simple) - Code",
    "section": "\n4.1 Step 1: Data reduction of omics data",
    "text": "4.1 Step 1: Data reduction of omics data\nUsing TriplotGUI package, first we perform dimension reduction, i.e. principal component analysis (PCA) on metabolomics data.\n\nCodereduced_Omics1&lt;-PCAorWGCNA_plots(dataframe=Omics1,\n                                 pc_num = 5,\n                                 option=\"PCA\")\n\n\nYou can see scree plot, score plot, loadings plot and biplot at this stage.\n\nCodereduced_Omics1$scree_plot\n\nplot\n\n\n\nCodereduced_Omics1$score_plot\n\nplot\n\n\n\nCodereduced_Omics1$loading_plot\n\nplot\n\n\n\nCodereduced_Omics1$scoreloading_plot\n\nplot\n\n\n\n\n\nWe then build a TPObject based on the data reduction result, which is used for saving information and pass them through steps in TriplotGUI.\n\nCodescores=reduced_Omics1$object$scores\nloadings&lt;-reduced_Omics1$object$loadings\nvariance&lt;- reduced_Omics1$object$variance\nTPObject1&lt;-makeTPO(scores=scores,\n                   loadings=loadings,\n                   variance=variance)\n\n\nMaking TriPlotObject (TPO)\n--------------------------\nLoading matrix has 20 variables and 20 components.\n\nScore matrix has 300 observations and 20 components.\n\nTPO has 0 attached correlations.\nTPO has 0 attached risks."
  },
  {
    "objectID": "simple_code.html#step-2-exposures-correlations-outcomes-associations",
    "href": "simple_code.html#step-2-exposures-correlations-outcomes-associations",
    "title": "Tutorial(simple) - Code",
    "section": "\n4.2 Step 2: Exposures’ correlations & Outcomes’ associations",
    "text": "4.2 Step 2: Exposures’ correlations & Outcomes’ associations\nThe correlations between principal component (PC) scores and food items were calculated using Pearson correlations, adjusting for confounders. The associations between PC scores and risk markers were investigated using linear regression (since all food variables are numeric).\nThe PC scores are saved in the TPObject and the TPObject can be directly used to calculate the correlation coefficients and p values with exposures(food variables) in the makeCorr() function, adjusting for confounders.\n\nCodeCorrelations_object&lt;-makeCorr(TPObject=TPObject1,\n                              corrData=exposure1,\n                              confounder=covariates1,\n                              method=\"pearson\")\n\n\nThe result of correlations are then added into the TPObject.\n\nCodeTPObject2&lt;-addCorr(TPObject=TPObject1,\n                   Corr=Correlations_object$cor_estimate,\n                   Corr_p=Correlations_object$cor_pvalue)\n\n\nAdding correlation to TPO\n-------------------------\nPlease ensure same number of components in TPO and correlation matrix\n\nTPO has 11 attached correlations.\nTPO has 0 attached risks.\n\n\nSimilarly, the risk estimates (beta coefficients from linear regression) and p values can be calculated from the PC scores saved in the TPObject and the outcome variables, adjusting for confounders.\n\nCodeRisks_object&lt;-coefficient_get(TPObject=TPObject2,\n                              outcome=outcome1,\n                              confounder=covariates1)\n\n\nThe result of risk estimates are then added into the TPObject.\n\nCodeTPObject3&lt;-addRisk(TPObject=TPObject2,\n                   Risk=Risks_object)\n\n\nAdding risk to TPO\n------------------\nPlease add risks one by one with component in rows and estimates, se:s and (optionally) p-values in columns\nPlease ensure same number of components in TPO and risk matrix\n\nTPO has 11 attached correlations.\nTPO has 5 attached risks."
  },
  {
    "objectID": "simple_code.html#step-3-visualization-of-triplot",
    "href": "simple_code.html#step-3-visualization-of-triplot",
    "title": "Tutorial(simple) - Code",
    "section": "\n4.3 Step 3: Visualization of Triplot",
    "text": "4.3 Step 3: Visualization of Triplot\nGenerate Triplot: Note that Triplot can be generated from any TPObject.\n\nCodeTriplot_object3&lt;-TriplotGUI(TPObject3,\n                            riskOR=F) #risks is shown as coeffcients, not odds ratio\n\n\nPlotting the triplot\n\nCodeTriplot_object3$triplot\n\nplot\n\n\n\n\n\nIn the triplot, PC1 reflected metabolites that were positively associated with BMI and also correlated with a high intake of meat and refined grains, adjusting for age and sex. This implies that the metabolite features that contributes most to PC1, are likely to provide useful information for a potential mechanism of how red meat and refrained grains intake may affect BMI."
  },
  {
    "objectID": "simple_code.html#step-4-mediation-analysis-and-visualization",
    "href": "simple_code.html#step-4-mediation-analysis-and-visualization",
    "title": "Tutorial(simple) - Code",
    "section": "\n4.4 Step 4: Mediation analysis and visualization",
    "text": "4.4 Step 4: Mediation analysis and visualization\nMediation analysis is then performed using the conventional “product” method on the our exposures (i.e. Refined grains, Red meat), mediators (i.e. PC1 and PC2) and outcome (i.e. BMI) of interest, adjusting for age and sex for both exposure-mediator and mediator-outcome relationship.\n\nCodemediation_object3&lt;-\n  get_mediation_traditional (mediator=TPObject3$scores[,c(1:2),drop=F], \n                             # Specfiying at least 2 components so that there can be a 2-dimensional plot\n                             exposure=exposure1[,c(\"Refined_grains\",\"Red_meat\"),drop=F],\n                             outcome=outcome1[,\"BMI\",drop=F],\n                             confounder_ME=covariates1,\n                             confounder_OE=covariates1)\n\n\nLook at the barplot to have a more direct view on direct, indirect and total effects for each combination\n\nCodemediation_plot_object3&lt;-plot_mediation(mediation_object3)\n\n\n\nCodemediation_plot_object3\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe barplot showed direct, indirect and total effect for each exposure-mediator-outcome combination. It is a convenient tool to check the direction and magnitude of mediation estimates. Red color represents significant positive effect (p&lt;0.05); Blue color represents significant negative effect (p&lt;0.05). Grey represents insignificant effect. One star for p&lt;0.05; Two stars for p&lt;0.01; Three stars for p&lt;0.001;\n\n\nAdd the mediation result into the TPObject.\n\nCodeTPObject4&lt;-add_mediation(TPObject3, mediation_object3)\n\n\nAdding mediation to TPO\n-------------------------\nNote that the exposures, mediators and outcomes are selected and not necessarily reflect total number of variables\n\nTPO mediation has used 2 mediators, 2 exposures, 1 outcomes\nMediators are PC1, PC2 \nExposures are Refined_grains, Red_meat \nOutcomes are BMItessssssssssssssssssssssss1111111111111111111111111111111111111111111111111111111111111111111111111111222222222222222222222222222222222222222222222222222222222222222222333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333320 EO_names20 PC_names20 estimates20 p_values20 mediation_estimate_names20 Exposure_names20 Outcome_namesPC1 PC1 PC2 PC2 PC1 PC1 PC2 PC2 PC1 PC1 PC2 PC2 PC1 PC1 PC2 PC2 PC1 PC1 PC2 PC2sddddddsdfggggggggggggggggggggggggggggggg444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444441.187396e-20 8.1822e-22 2.315783e-06 1.4264e-06 0.4505731 0.1003014 0.001111641 0.003746183 0.002361381 0.01371697 0.002361381 0.01371697 0.0006457253 0.004530111 0.00866911 0.0272195 0.0006457253 0.004530111 0.00866911 0.027219520201234567891011121314151617181920DoneDONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNnnntesssssssssssssssssssssssssssssssssssssstesssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss\n\n\nMake the triplot with mediation.\n\nCodeTriplot_object4&lt;-mediation_triplot(TPObject4,\n                                   which_show = c(\"IE\",\"TE\")\n                                   )\n\n\nOnly showing the mediation estimates (indirect and total effect).\n\nCodeTriplot_object4$mediation_plot\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe indirect effect is presented as triangle points and the total effect is presented as circles. While indirect effect can only be presented with a mediator(e.g. PC1, PC2), total effect is always there and the value remains the same for specific exposure-outcome pairs, regardless of which mediation analysis we want to present in the figure.\n\n\nPlotting the triplot with mediation\n\nCodeTriplot_object4$final_plot\n\nplot\n\n\n\n\n\nBase on the barplot and the triplot with mediaiton, we observed a significant mediation effect through PC1 for Red_meat-BMI and refined_grain-BMI association. This further implies that the metabolite features that contributes to PC1 are likely to mediate the pathway from red meat and refined grain intake to BMI change."
  },
  {
    "objectID": "simple_code.html#step-5-compare-correlations-associations-and-mediations",
    "href": "simple_code.html#step-5-compare-correlations-associations-and-mediations",
    "title": "Tutorial(simple) - Code",
    "section": "\n4.5 Step 5: Compare correlations, associations and mediations",
    "text": "4.5 Step 5: Compare correlations, associations and mediations\nUsers can check the heatmaps of correlations, risk estimations and mediation results from the TPObject through the checkTPO_ggplot() function in TriplotGUI.\n\nCodecheckTPObject4&lt;-checkTPO_ggplot(TPObject4)\n\n\nCorrelation coefficients and p values between PC scores and exposures:\n\nCodecheckTPObject4$corr_coefficients\n\nplot\n\n\n\n\n\nRisk estimates(beta coefficients) and p values between PC scores and outcomes:\n\nCodecheckTPObject4$risk_coefficients\n\nplot\n\n\n\n\n\nMediation estimates and p values for indirect effect(IE), direct effect(DE) and total effect(TE), proportion mediated(PM) and adjusted proportion mediated(APM): See Details for more details:\n\nCodecheckTPObject4$med_coefficients\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nOne star for p&lt;0.05; Two stars for p&lt;0.01; Three stars for p&lt;0.001.\nNote that in the plot of checkTPbject4$med_coefficients, only the selected exposures, mediators and outcomes that we use to do mediation on will show up. The rows in the heatmaps are mediators and the column represents exposure-outcome pairs. For each exposure_outcome pair, 5 result are shown: IE (indirect effect), DE (direct effect), TE (total effect), PM(Proportion Mediated) and APM(Adjusted Proportion Mediated). Please see Details section for more information. The “BK” before the names of exposures-outcome pairs means that this mediation is using the Coventional Baron-Kenny “product” method."
  },
  {
    "objectID": "simple_code.html#step-6-download-data",
    "href": "simple_code.html#step-6-download-data",
    "title": "Tutorial(simple) - Code",
    "section": "\n4.6 Step 6: Download data",
    "text": "4.6 Step 6: Download data\nWe can save all your output, including data, results and visualization output through the save() function as an rda file.\n\nCodesave(exposure1,Omics1,outcome1,covariates1,\n     reduced_Omics1,Correlations_object,Risks_objects,\n     mediation_object3,mediation_plot_object3,\n     TPObject1,TPObject2,TPObject3,TPObject4,\n     checkTPObject4,\n     \"Tutorial_simple_output.rda\")"
  },
  {
    "objectID": "use_case.html",
    "href": "use_case.html",
    "title": "Use case - User Interface",
    "section": "",
    "text": "Before starting, please make sure you have installed the TriplotGUI package following Setup."
  },
  {
    "objectID": "use_case.html#step-1-data-reduction-of-omics-data-and-auxiliary-data",
    "href": "use_case.html#step-1-data-reduction-of-omics-data-and-auxiliary-data",
    "title": "Use case - User Interface",
    "section": "Step 1: Data reduction of Omics data and auxiliary data",
    "text": "Step 1: Data reduction of Omics data and auxiliary data\nFirst upload the Omics data in step 1. Inspect the classes of Omics variables briefly. Explore that data using the “Data analysis settings” and “Visualization setting” to select 2 component of interest. We will use the following settings as an example, but of course you can use your own settings. Examine the scree plot, score plot, loadings plot and biplot at step 1 for your choice."
  },
  {
    "objectID": "use_case.html#step-2-exposures-correlations-outcomes-associations",
    "href": "use_case.html#step-2-exposures-correlations-outcomes-associations",
    "title": "Use case - User Interface",
    "section": "Step 2: Exposures’ correlations & Outcomes’ associations",
    "text": "Step 2: Exposures’ correlations & Outcomes’ associations\nThen upload exposures and covariate data in step 2A. Briefly inspecting variable classes, remove the variables you don’t want. Set your own “Data analysis settings”. In our example\n\n\n\n\n\n\n\n\n\nChange your “Data analysis settings” as the figure below.\n\n\n\n\n\n\nNote\n\n\n\n\nSelect One-hot-encoding in Categorical variables performs one-hot-encoding to transform categorical exposures variables (i.e. HFI) with n&gt;2 classes to n binary variables. If Use Original is specified in Categorical variables, then the HFI variable is forced to be a numeric variable. This is not recommended unless you are sure that the level itself reflects the numeric value.\nThe approaches for managing Missing values are inherited from the cor package for continuous exposures. Please check cor package for more information.\n\n\n\n\n\n\nYou could briefly see the correlation coefficients in “Visualizations” by clicking “Refresh plot”.\n\n\n\n\n\n\nThen in step 2B, upload outcome and covariate data By briefly inspecting variable classes, you could notice: - In the outcome data, \"BMI\" is a numeric variable; \"BMI_cat\" and \"T2D\" are factor variables. - A variable called \"X\" exists in the covariate data. This is because the covariate data is uploaded as a csv file and the observation number may automatically be generated as a new variable when the file is read in. Remove this variable since it is not an actual covariate.\n\n\n\n\n\n\n\n\n\nChange your “Data analysis settings” and “Visulization settings” as the figure below.\n\n\n\n\n\n\nNote\n\n\n\nSome clarification for using multinomial regression and pairing variables:\n\nWhen a pairing variable is not provided:\n\nNot performing multinomial regression means that one-hot-encoding will be performed to transform outcome’s categorical variables with n &gt; 2 classes to n binary variables. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables.\nPerforming multinomial regression means that multinomial regression will be performed on outcome’s categorical outcome variable with n &gt; 2 classes, which gives n-1 estimates. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables.\n\n\nWhen a pairing variable is provided:\n\nNot performing multinomial regression means that one-hot-encoding will be performed on outcome’s categorical variables with n &gt; 2 classes. And then conditional logistic regression will be performed on the binary variables and linear mixed model will be performed on continuous variables, using the pairing information.\nPerforming multinomial regression means that the pairing information will not be ignored and used (since the outcomes can have more than 2 classes), multinomial regression will be performed on outcome’s categorical variable, which gives n-1 estimates. And logistic regression will be performed on the binary variables and linear regression will be performed on continuous variables. THIS IS THE CASE IN OUR EXAMPLE.\n\n\n\n\n\n\n\n\n\n\n\nYou could briefly see the risk estimate in “Visualizations” by clicking “Refresh plot”."
  },
  {
    "objectID": "use_case.html#step-3-visualization-of-triplot",
    "href": "use_case.html#step-3-visualization-of-triplot",
    "title": "Use case - User Interface",
    "section": "Step 3: Visualization of Triplot",
    "text": "Step 3: Visualization of Triplot\nIn step 3, by clicking “Refresh plot”, you can see and download the triplot that co-visualizing the three plots shown above. The left side panel gives you freedom of making adjustment to the plot. \nIn the triplot, blue circle points represent exposure correlations and the red square points represents outcome risk estimates with confidence interval. So what information can we get from this figure? Lets us list a few points:\n\nHaving a brief look, the generally healthy food (e.g. \"Fruits\", \"Vegetables\") is on the first dimension of the figure and the generally unhealthy food (e.g. \"Hamburger\", \"Sausage\", \"Margarine\") is on the third dimension of the figure. The numeric outcome \"BMI\", binary outcome \"T2D\", and one-hot-encoded categorical \"BMI_cat\" outcome is on the second and fourth dimension of the figure.\nExplanation on some variables in the plot:\n\n\n\"HFI\" stands for healthy food index. A higher \"HFI\" suggests healthier diet. \"HFI\" ranges from 0 to 6. You can see that there are HFI_0, HFI_1…HFI_6 in the figure and that is because \"HFI\" is used as a factor exposure variable in step 2 and is one-hot-encoded (´allowcategorical=F´) to the same number of binary variables as its number of levels. For example, HFI_6 is a binary variable where individuals with \"HFI 6\" (most healthy diet people) will be labeled as 1 and the rest of individuals will be labelled as 0. HFI_0 is a binary variable where individuals with \"HFI 6\" (most unhealthy diet people) will be labeled as 1 and the rest of individuals will be labelled as 0. HFI_1…HFI_5 has limited use since it only separates the group of people with certain \"HFI\" from to the rest, which is a mixture of healthier and less healthier diet people.\n\n\"BSDS\" stands for Baltic Sea Diet Score ranging. A higher \"BSDS\" suggests healthier diet. \"BSDS\" is used as a numeric variable ranging from 2 to 25 in this step.\n\nT2D_1 represents the odds ratio of \"T2D\". Since \"T2D\" is a binary variable with 0(control) and 1(case) level. A logistic regression is performed on the \"T2D\", and 0 is used as reference. That is why it shows T2D_1 on the plot.\n\nBMI_cat_obese, BMI_cat_overweight,BMI_cat_underweight are the odds ratio generated from the multinomial regression. Since \"BMI_cat\" is a categorical outcome and multinomial regression is performed in step 2 (multinomial=T), normal weight is uses as a reference and odds ratio of obese, overweight and underweight is produced. (Note that the first level of the factor variable is set as the default reference, in this case it is normal.\n\n\nAdjusting for \"Age\", \"Gender\", \"Smoking\", \"Education\" and \"FastingGlucose\", component from the first cluster (on x-axis) correlates positively with generally healthy food (e.g. \"fruits\", \"vegatables\") and food index (e.g. \"BSDS\") and negatively with unhealthy food (e.g. \"Hamburger\", \"pizza\"). It also reversely associated with \"T2D\" and \"BMI\". From the result from \"BMI_cat\", this components also reversely associated with being obese. This suggests that metabolite features from the first cluster may contribute to the mechanism from food to the incidence of T2D and obese\nComponent from the second cluster (on y-axis) associated positively with generally healthy food (e.g. \"fruits\", \"vegatables\") and food index (e.g. \"BSDS\") and negatively with unhealthy food (e.g. \"Hamburger\", \"pizza\"). However, the component correlates also positively with \"T2D\",\"BMI\", obese, overweight and negatively associated with underweight. This suggests that metabolite features from the second cluster may be relevant to the mechainism of weight gain through healthy food (or a weight loss through unhealthy food)\n\nThere are many things you could explore further in the following mediation analysis. To narrow down our focus and clearly show our examples, we select \"BSDS\" (Baltic Sea Diet Score) and \"Hamburger\" as our exposures, \"BMI\" and \"T2D\" as outcome to enter our next step."
  },
  {
    "objectID": "use_case.html#step-4-mediation-analysis-and-visualization",
    "href": "use_case.html#step-4-mediation-analysis-and-visualization",
    "title": "Use case - User Interface",
    "section": "Step 4: Mediation analysis and visualization",
    "text": "Step 4: Mediation analysis and visualization\nThis time, we perform the mediation analysis using the conterfactual/potential outcome method (the ´mediation´ package) on the our exposures (i.e. \"BSDS\", \"Hamburger\"), mediators (i.e. the first PC of the first 2 clusters) and outcome (i.e. \"T2D\", \"BMI\") of interest, adjusting for \"Age\", \"Gender\", \"Smoking\", \"Education\" and \"FastingGlucose\" for both exposure-mediator and mediator-outcome relationship.\n\n\n\n\n\n\nNote\n\n\n\nIn the counterfactual mediation analysis, you need to specify contrast values of treatment and controls for each exposure. In brief, the algorithm will compare the scenarios with these 2 exposure values/levels. For my detailed explanation please refer to this paper of the mediation R package.\nIf an exposure variable is continuous (numeric variable), it is recommended that the 2 exposure values is chosen between the range of the exposure variable. If an exposure variable is categorical (factor variable), the 2 exposure levels should be chosen from the levels of the exposure variable.\n\n\n\n\nUse the following settings for your data analysis. Mediation analysis is then performed using the counterfactual method on the our selected exposures, mediators and our selected outcomes, adjusting for covariates for both exposure-mediator and mediator-outcome relationship.\n\n\n\n\n\n\nNote\n\n\n\n\nNote that you need to click Do mediation to start running the mediation analysis.\n\n\n\n\n\n\n\n\nYou could then play around in the “Visualization settings” too see how you want to visualize your plot.\n\n\n\nYou could first only show the proportion mediated(PM) and adjust the limits to make the points more visible. \n\n\n\n In the figure, even though not significant, we could see the direction and magnitude of proportion mediated for the 2 mediators, all the exposures and outcomes.\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nNote that some confidence intervals are automatically removed form the figure if they are not within the limit.\nNote that for some mediations, direct effect and indirect effects are in the opposite direction, implying possibly proportion mediated&gt;1, since total effect could smaller than indirect effect.\n\n\n\n\n\nYou then show the adjusted proportion mediated(PM) and adding the layers of correlation and risk estimates \n\n\n\n\n\n\nBy observing this figure, we could see the direction and magnitude of adjusted proportion mediated for the 2 mediators, all the exposures and outcomes. The position of the points is similar what we have seen for proportion mediated. Note that APM for BSDS as exposure and T2D as outcome is smaller than their PM. This is because the indirect and direct effect for this mediation is of similar size but in opposite direction. This leads to a smaller total effect and in turn larger PM, but APM will not be affected by the directionality of direct and indirect effect. ::: callout-note - No confidence interval is shown for adjusted proportion mediated, as such value can not be directly calculated from the mediation analysis.\n\nNote that even direct effect and indirect effects are in the opposite direction, adjusted proportion mediated is always smaller than 1, since it uses the sum of the absolute value of indirect and direct effect as denominator. \\[APM=\\frac{IE}{|IE|+|DE|}\\cdot\\frac{|IE+DE|}{IE+DE}=\\frac{IE}{IE+DE}\\cdot\\frac{|IE+DE|}{|IE|+|DE|}=\\frac{IE}{IE+DE}\\cdot\\frac{|IE|+|DE|}{|IE+DE|}\\] :::\n\nIn step 4, you can also see the barplots showed direct, indirect and total effect for each exposure-mediator-outcome combination. It is a convenient tool to check the direction and magnitude of mediation estimates."
  },
  {
    "objectID": "use_case.html#step-5-compare-correlations-associations-and-mediations",
    "href": "use_case.html#step-5-compare-correlations-associations-and-mediations",
    "title": "Use case - User Interface",
    "section": "Step 5: Compare correlations, associations and mediations",
    "text": "Step 5: Compare correlations, associations and mediations\nUsers can then check the heatmaps of correlations, risk estimations and mediation results at step 5. By removing other PCs, exposures or outcomes in the “Visualization settings”, users may only show correlation, risk estimation and mediation results of their interest."
  },
  {
    "objectID": "use_case.html#step-6-download-data",
    "href": "use_case.html#step-6-download-data",
    "title": "Use case - User Interface",
    "section": "Step 6: Download data",
    "text": "Step 6: Download data\nRelevant data, intermediate results, can then be viewed and downloaded at step 6."
  },
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "We will go through the statistical analysis behind TriplotGUI and also explain the details of out data analysis and visulization in each step. If you want to search the meaning of something specific (e.g. a button, a box), please press ctrl+F and enter the keyword, you will probably find what you need.\nIf you have not open the app yet, follow what is written in the Setup and open the interface with TriplotGUI_shiny()"
  },
  {
    "objectID": "workflow.html#data-for-pcawgcna",
    "href": "workflow.html#data-for-pcawgcna",
    "title": "Workflow",
    "section": "\n1.1 Data for PCA/WGCNA",
    "text": "1.1 Data for PCA/WGCNA\n\n1.1.1 Basics\nThe darkblue box is where you put in the Omics data. The data should meet the following criteria.\n\nThe data should be in either csv, xlsx, rds, or rda format. The data in rds format should be a dataframe. If the data is in rda format, the rda object should only contain the data as a dataframe and be in the same directory as your working directory (You could check this by getwd() in the R console)\nThe rows of data should represent observations and the columns of data should represents variables(omics features).\nThe names of variables (column names) should not contain special characters including ' ', '(', ')', ':', '/', '-', ',', '@'.\nNo missing values are allowed in the data\nThe number and order of observations should be same across all the uploaded data\n\n\n\n\n\n\n\nNote\n\n\n\nWe do not provide the functionality of handling missing data or other data pre-processing steps (e.g. transformation, normalization) in our application due to the variability of possible methods.\n\n\n\n1.1.2 Emerged\nAfter you upload the data, A text will show up to tell you how many rows and columns do you have in the data frame. Three following buttons also emerge: Inspect variable class(es), remove variables(s), Force all variables to numeric.\n\nInspect variable class(es) This is a button that help you inspect if the variables are in correct format, since you may not want your metabolite features in character format when you want to use their numeric values. Click the button and explore.\n\nremove variable(s): This button allows you to remove variables from your uploaded data. Click the button, remove some variables and click OK. What variables are removed are then printed out and they will not be included in the Omics data to enter the downstream analysis. We also make this removal reversible so that every time when you reclick this button, the data will go back to the state where no variables are removed.\nWe add this button so that users will not need to manually remove redundant variables that will actually not be used in data analysis.\n\nForce all variables to numeric: Upon clicking, this button simply forces all the variables to numeric. Since we want to perform PCA or WGCNA on this Omics data, we want all Omics variables to be in numeric format\n\n1.1.3 And more\nAt the right side of the upload data, there is a button called Reset everything. This where you can click remove all your uploads and settings and make the interface go back to a default state."
  },
  {
    "objectID": "workflow.html#auxilary_data",
    "href": "workflow.html#auxilary_data",
    "title": "Workflow",
    "section": "\n1.2 Auxilary data",
    "text": "1.2 Auxilary data\nThe lightblue box is where you put in the auxilary data. Currently, the variables in the data uploaded here can be used for 2 things (1) Customizing the color, size and shape of scores. See section 1.4.2. (2) Providing pairing information for outcomes’ associations. See section 1.1.1.\n\n1.2.1 Basics\nThe requirement for input data is the same as 1.1.1.\n\n1.2.2 Emerged\nAfter you upload the axuliary data, A text will show up to tell you how many rows and columns do you have in the data frame. Three following buttons also emerge: Inspect variable class(es), remove variable(s), Change variable class.\n\nInspect variable class(es) Same as 1.1.2\nremove variable(s): Same as 1.1.2\n\nChange variable class: This button provide your choices in transforming variables to either factor and numeric variables.\nWe add this button to faciliate user in tranforming variables to numeric and factor format, corresponding to numeric and caregorical variables."
  },
  {
    "objectID": "workflow.html#data-analysis-settings",
    "href": "workflow.html#data-analysis-settings",
    "title": "Workflow",
    "section": "\n1.3 Data analysis settings",
    "text": "1.3 Data analysis settings\nThe red box is where you make choices in how do you want your data analysis to be performed.\n\n1.3.1 Basics\n\nMethod: Users choose to either use principal component analysis (PCA) or weighted correlation network analysis (WGCNA) to perform data reduction. The default is PCA\nPCA function: Users choose what PCA function, prcomp or principal, will be used for principal component analysis. The default is prcomp\n\nMax number of components: This button shows up when the Method is PCA. It decides how many principal component will be used in the downstream correlation& association analysis. The default is set as 5 or the number of variables int he omics data (if smaller than 5).\nMinimum number for variables per module: This button shows up when the Method is WGCNA. It decides the minimum number of variables that is allowed in each cluster of WGCNA. The default number is 2.\n\nCenter: If the omics variables will be zero centered before the analysis take place. The default is Yes.\nScale: If the omics variables will be scaled to have unit variance before the analysis take place. The default is Yes.\n\n1.3.2 Emerged\n\n\nrotation: The button will show up and When PCA function is chosen as principal. It allows users to select how they would like to transform principal components. Please check here for the explanation fo rotate. The default is set as none in TriplotGUI.\n\n\n\n\n\n\n\nNote\n\n\n\nYou maybe heard about PCA but not WGCNA. In brief, WGCNA is to separate omics variables into clusters, perform PCA on each cluster and extract the first principal component of each cluster as the principal components of WGCNA. The clustering method can be different. In TriplotGUI, we use the default hierarchical clustering method provided by cutreeDynamic() in the dunamicTreeCut package"
  },
  {
    "objectID": "workflow.html#visualization-settings",
    "href": "workflow.html#visualization-settings",
    "title": "Workflow",
    "section": "\n1.4 Visualization settings",
    "text": "1.4 Visualization settings\nThe orange box is where users can modify their visulization outputs\n\n1.4.1 Basics\n\nPlotting options: Four options are provided: (1) scores: The scores of principal components are plotted. (2)loadings: The loadings of principal components are plotted. (3) biplots: Both scores and loadings are plotted on the same plot. (4) screeplot: How much variance does each principal component contribute to is plotted. In default mode, none of the 4 options are selected.\nComponent/module on first axis: The principal component that will be plotted on the x-axis. The default is 1 (the first one).\nComponent/module on second axis: The principal component that will be plotted on the y-axis. The default is 2 (the second one).\nType of loadings: Two options are provided Eigenvectors and Eigenvectors × squareroot(eigenvalues). The 2 calulations, respectively, correspond to what is referred to as “rotation” in the prcomp package and “Loadings” in the principal package.\n\n1.4.2 Emerged\n\nLoading labels: Upon clicking loadings or biplot in Plotting options. The button will show up. It decides if labels of loadings will be shown on the plot. The default is Yes.\nLoading Cut by: Upon clicking loadings or biplot in Plotting options, the button will show up. It is useful when the users only want to show loadings bigger than an absolute value or bigger than a certain percent of the maximum loading. The default is Absolute.\nAbsolute loading length: When selecting Absolute in Loading Cut by, a slider will show up to let user decide the loadings below what value will not show up on the plot.\nProportion of maximum loading: When selecting Proportion in Loading Cut by, a slider will show up to let user decide the loadings below how much percent of the maximum loading will not show up on the plot.\nScore color by: Upon uploading the Auxilary data and clicking loadings or biplot in Plotting options, this button will show up. Users can use one numeric or categorical variable in the auxilary data to color the scores points. By default, no variables are selected.\nScore shape by: Upon uploading the Auxilary data and clicking loadings or biplot in Plotting options, this button will show up. Users can use one categorical variable in the auxilary data to change the shape of scores points. By default, no variables are selected.\nScore size by: Upon uploading the Auxilary data and clicking loadings or biplot in Plotting options, this button will show up. Users can use one numeric variable in the auxilary data to change the size of score points. By default, no variables are selected."
  },
  {
    "objectID": "workflow.html#visualizations",
    "href": "workflow.html#visualizations",
    "title": "Workflow",
    "section": "\n1.5 Visualizations",
    "text": "1.5 Visualizations\nThe green box represents visualization outputs. With omics data uploaded, upon selecting Plotting options in the data visualization setting, the corresponding plot are shown."
  },
  {
    "objectID": "workflow.html#exposure-data",
    "href": "workflow.html#exposure-data",
    "title": "Workflow",
    "section": "\n2.1 Exposure data",
    "text": "2.1 Exposure data\n\n2.1.1 Basics\nThe dark blue box is where you put in the exposure data. The requirement for exposure data is the same as 1.1.1.\n\n2.1.2 Emerged\nAfter you upload the exposure data, A text will show up to tell you how many rows and columns do you have in the data frame. Three following buttons also emerge: Inspect variable class(es), remove variable(s), Change variable class.\n\nInspect variable class(es) Same as 1.1.2\nremove variable(s): Same as 1.1.2\nChange variable class: Same as 1.2.2"
  },
  {
    "objectID": "workflow.html#Covaraite_data1",
    "href": "workflow.html#Covaraite_data1",
    "title": "Workflow",
    "section": "\n2.2 Covariate data",
    "text": "2.2 Covariate data\nThe light blue box is where you put in the covariate data. After removing redundant variables, the remaining covariate data can be used as confounders for the partial correlation between exposures and principal components.\n\n2.2.1 Basics\nThe requirement for exposure data is the same as 1.1.1.\n\n2.2.2 Emerged\nAfter you upload the covariate data, A text will show up to tell you how many rows and columns do you have in the data frame. Three following buttons also emerge: Inspect variable class(es), remove variable(s), Change variable class.\n\nInspect variable class(es) Same as 1.1.2\nremove variable(s) Same as 1.1.2\nChange variable class: Same as 1.2.2"
  },
  {
    "objectID": "workflow.html#data-analysis-settings-1",
    "href": "workflow.html#data-analysis-settings-1",
    "title": "Workflow",
    "section": "\n2.3 Data analysis settings",
    "text": "2.3 Data analysis settings\nThe red box is where you make choices in how do you want your correlation analysis to be performed\n\n2.3.1 Basics\n\nMethod: Three methods inherited from the cor package are supported for continuous exposures: Pearson, Spearman, Kendall. Please check cor package for more information. The default for TriplotGUI is Spearman.\nMissing values: The approaches for managing missing values inherited from the cor package are supported for continuous exposures. Please check cor package for more information. The default for TriplotGUI is everything.\nCategorical variables: Two options are provided Perform one-hot-encoding and Use original. When choosing Perform one-hot-encoding, categorical variables with n classes(n&gt;2) are transformed to n binary variables with 0 and 1 values and then used as numeric variables. When chosing Use original, no transformation is made on the categorical variabls and linear models are used for categorical exposure-principal component correlation analysis. The default is Use original.\n\n2.3.2 Emerged\n\n\nRaw or partial correlation: Upon uploading the covariate data, the button will show up. Two options are provided: Raw and Adjusted. Raw means no covariates are used as confounders in the correlation analysis and Adjusted means that partial correlations, adjusting the same group of confounders, are performed on all exposures-principal components correlations."
  },
  {
    "objectID": "workflow.html#visualizations-1",
    "href": "workflow.html#visualizations-1",
    "title": "Workflow",
    "section": "\n2.4 Visualizations",
    "text": "2.4 Visualizations\nThe green box represents visualization outputs. With omics data from step 1 and exposure data uploaded, upon clicking the Refresh plot button, the correlations between exposures and the 2 selected components (selected from step 1) are shown. The figure can be downloaded by clicking Download figure."
  },
  {
    "objectID": "workflow.html#outcome-data",
    "href": "workflow.html#outcome-data",
    "title": "Workflow",
    "section": "\n3.1 Outcome data",
    "text": "3.1 Outcome data\n\n3.1.1 Basics\nThe dark blue box is where you put in the outcome data. The requirement for exposure data is the same as 1.1.1.\n\n3.1.2 Emerged\nAfter you upload the exposure data, A text will show up to tell you how many rows and columns do you have in the data frame. Three following buttons also emerge: Inspect variable class(es), remove variable(s), Change variable class.\n\nInspect variable class(es) Same as 1.1.2\nremove variable(s): Same as 1.1.2\nChange variable class: Same as 1.2.2"
  },
  {
    "objectID": "workflow.html#Covaraite_data2",
    "href": "workflow.html#Covaraite_data2",
    "title": "Workflow",
    "section": "\n3.2 Covariate data",
    "text": "3.2 Covariate data\nThe light blue box is where you put in the covariate data. After removing redundant variables, the remaining covariate data can be used as confounders for the partial correlation between outcomes and principal components.\n\n3.2.1 Basics\nThe requirement for exposure data is the same as 1.1.1.\n\n3.2.2 Emerged\nAfter you upload the covariate data, A text will show up to tell you how many rows and columns do you have in the data frame. Three following buttons also emerge: Inspect variable class(es), remove variable(s), Change variable class.\n\nInspect variable class(es) Same as 1.1.2\nremove variable(s): Same as 1.1.2\nChange variable class: Same as 1.2.2"
  },
  {
    "objectID": "workflow.html#data-analysis-settings-2",
    "href": "workflow.html#data-analysis-settings-2",
    "title": "Workflow",
    "section": "\n3.3 Data analysis settings",
    "text": "3.3 Data analysis settings\nThe red box is where you make choices in how do you want your risk association analysis to be performed.\n\n\n\n\n\n\nNote\n\n\n\nFor outcomes - principal-components associations, statistical analysis are performed differently based on different classes of outcome and information provided. The table below summarized the methods and R packages used.\n\n\n\n\n3.3.1 Basics\n\n\nlog(risk): Users can choose whether they want their risk estimations to be presented as beta coefficients or odds ratios. Two options are provided Yes (useful for odds ratio) and No (useful for beta coefficient). The default is No (useful for beta coefficient)\n\n\n3.3.2 Emerged\n\nConfounder adjustment: Upon uploading the covariate data, the button will show up. The users can choose if confounder will be adjusted for all outcomes-principal components associations, using the same group of confounders. The default is No.\nMultinomial Regression: If categorical variables with n&gt;2 class is uploaded or created from outcome variables, the button will show up. By selecting No, one-hot-encoding will be performed on these categorical variables to transform them to n binary variables with 0 and 1 values. By selecting Yes, multinomial regression will be performed on these categorical variables. The default is No.\nPairing variable: When auxilary data (1.2.1) is uploaded, this button will show up. It allows users to select variables that contain pairing information in the auxilary data. For example, the matched case-control pair could constitute a categorical variable, where each pair of case and control is given a unique number. Such information can be fed in the modelling of outcome-principal components associations."
  },
  {
    "objectID": "workflow.html#visualization-settings-1",
    "href": "workflow.html#visualization-settings-1",
    "title": "Workflow",
    "section": "\n3.4 Visualization settings",
    "text": "3.4 Visualization settings\nThe orange box is where users can modify their visulization outputs\n\n3.4.1 Basics\n\nConfidence level: The confidence level used when calculating the confidence interval of risk estimate.The default is 0.95.\nWhisker length:The whisker length of confidence intervals in the figures. Change it from 0.1 to 0.5 and see what is changed in Visualizations! The default is 0.1."
  },
  {
    "objectID": "workflow.html#visualizations-2",
    "href": "workflow.html#visualizations-2",
    "title": "Workflow",
    "section": "\n3.5 Visualizations",
    "text": "3.5 Visualizations\nThe green box represents visualization outputs. With Omics data from step 1 and outcome data uploaded, upon clicking the Refresh plot button, the risk associations between outcomes and 2 selected components (selected from step 1) are shown. The figure can be downloaded by clicking Download figure."
  },
  {
    "objectID": "workflow.html#visualization-settings-2",
    "href": "workflow.html#visualization-settings-2",
    "title": "Workflow",
    "section": "\n4.1 Visualization settings",
    "text": "4.1 Visualization settings\nThe orange box represents visualization settings.\n\nComponent/module on first/second axis: The principal component that will be plotted on the x/y-axis. The default is 1/2 (the first/second one).\nPlot loadings/correlations/risks: Whether loadings, correlations and risk estimates will be plotted on the visualization. The default is Yes. Upon selecting a No, buttons that are relevant to plot loadings/correlations/risks will not show up.\nLoading/Correlation/Risk Labels Whether the labels of loadings, correlations and risk estimates will be plotted on the visualization. The default is Yes for correlation and risk labels and No for loading labels.\nLoading/Correlation/Risk Limits The limits of loadings, correlations and risk estimates on the visualization. The default is set as 1.1 times of the maximum loading value, 1.1 times of the maximum correlation coefficients, 1.1 times of the maximum value for risk estimates’ confidence intervals.\nArrow tip length: The arrow tip length of loadings. The default is 0.02.\nLoading Cut: Loadings below the value will not show up on the plot.\nPlot Scores: Whether the scores will be plotted. The default is No.\nWhisker length: The whisker length of confidence intervals in the figures. Change it from 0.1 to 0.5 and see what is changed in Visualizations! The default is 0.1.\nlog(risk): Users can choose whether they want their risk estimates to be presented as beta coefficients or odds ratios. Two options are provided Yes (useful for odds ratio) and No (useful for beta coefficient). The default is No (useful for beta coefficient)."
  },
  {
    "objectID": "workflow.html#triplot",
    "href": "workflow.html#triplot",
    "title": "Workflow",
    "section": "\n4.2 Triplot",
    "text": "4.2 Triplot\nThe green box represents visualization outputs. With Omics data from step 1 and outcome data uploaded, upon clicking the Refresh plot button, the risk associations between outcomes and 2 selected components (selected from step 1) are co-visualized. The figure can be downloaded by clicking Download figure."
  },
  {
    "objectID": "workflow.html#data-analysis-settings-3",
    "href": "workflow.html#data-analysis-settings-3",
    "title": "Workflow",
    "section": "\n5.1 Data analysis settings",
    "text": "5.1 Data analysis settings\n\n5.1.1 Basics\n\nComponent/module on first/second axis: The principal component that will be plotted on the x/y-axis. The default is 1/2 (the first/second one).\nType of mediation analysis: Two options are provided, Coventional and Counterfactual. By selecting Coventional, mediation analysis originated from Baron and Kenny and based on the product method will be performed. By selecting Counterfactual mediation analysis, a potential outcome framework provided by the mediation package is used. Here is a summarizarion of these 2 methods in TriplotGUI.\n\n\n\n5.1.2 Emerged\n\nExposure variables: This button will show up upon exposure data is uploaded in step 2. Users can choose which exposures they want to include in their mediation analysis.\nOutcome variables: This button will show up upon outcome data is uploaded in step 2. Users can choose which exposures they want to include in their mediation analysis.\nTreatment/control: When the mediation method is not selected or selected as Counterfactual, this button will show up upon exposure data is uploaded in step 2 and exposures for mediation analysis are selected. For each selected exposure variables, users needs to specify two values (for continuous exposures) or two classes (for categorical exposures) as treatment and control contrast, respectively.\n\n\n\n\n\n\n\nNote\n\n\n\nWhen the mediation method is selected as Counterfactual. It is a must that all treatment and control contrast values are specified before running mediation analysis and that the treatment and control values are different.\nIf the exposure variable is numeric, the range will be printed out and it is recommended that the users specify treatment and control contrast values between this range. If the exposure variable is categorical, how many levels in the exposure variable will be printed out. Users can only select the existing levels.\n\n\n\n5.1.3 Running mediation analysis\nClick when add new variables/ run with different methods:\nAfter the users select the exposures and outcomes that they want to perform mediation analysis on, unlike previous steps that automatically performs analysis upon uploading data, the users need to click the Do mediation button to start running mediation analysis, due to the time mediation analysis may take. (Mediation analysis will be performed on the each combination of exposure, principal component and outcome).\nUpon clicking, the button will turn grey. A progress bar will then show up at the right bottom corner to remind users if mediation analysis is still running (since it may take sometime). After running mediation analysis, the progress bar will disappear and the button itself will change back to white color.\n\n\n\n\n\n\nNote\n\n\n\n\nThe interface memorizes what mediation analysis has been run (e.g. Using what exposure, what outcome, what method). This means that once you have run mediation analysis on certain exposures and outcomes, even if you unselect an exposure or outcome, their mediation result are not deleted. You can check this by reselecting the unselected exposure/outcome and click Do mediation. You may notice that the mediation analysis is finished rather fast since the result is already there.\nYou can run Counterfactual and conventional analysis alternatively on the same exposure-outcome pair. The result for different methods will be saved respectively.\nFor a Counterfactual mediation analysis, if you have used exposures-outcomes pairs to run mediation analysis, given specific treatment or control values for exposures, once you use a different treatment or control values for an exposure, all the mediation analysis connecting with that exposure will be rerun and the new results will replaces the corresponding old ones. The last-used treatment and control values for running mediation analysis will be memorized and show up in the Treatment and Control.\n\nCounterfactual mediation analysis may take more time to run Traditional mediation analysis.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\nBy selecting exposures, outcomes and specifying mediation method and then clicking Do mediation, the mediation analysis will be run and the results will be saved for the selected exposures, outcomes and mediation methods.\nVisualization will be based on what is selected in the Data analysis settings and set up in the Visualization settings. And the visualization will only show the results (using specific exposures, outcomes and mediation methods) that are saved."
  },
  {
    "objectID": "workflow.html#simple_code_link",
    "href": "workflow.html#simple_code_link",
    "title": "Workflow",
    "section": "\n5.2 Visualization settings",
    "text": "5.2 Visualization settings\n\nPlot meditation/correlations/risks: Whether mediations, correlations and risk estimates will be plotted on the visualization. The default is Yes. Upon selecting a No, buttons that are relevant to plot mediation/correlations/risks will not show up.\nMediation/correlation/risk Labels Whether the labels of mediation, correlations and risk estimates will be plotted on the visualization. The default is Yes for mediation, correlation and risk labels.\nMediation/correlation/risk Limits The limits of mediations, correlations and risk estimates on the visualization. The default value is set as the same value in step 3 for correlation and risk Limits. The default value for mediation limits is set as 1.1 times of the maximum value for mediation results’ confidence intervals.\nWhisker length for mediations/risks: The whisker length of confidence intervals in the figure. Change it from 0.1 to 0.5 and see what is changed in Visualizations! The default is 0.1.\nMediation proportion or estimate: Two options are provided, Proportion and Estimate. Upon selecting Proportion, the proportion mediated (The impact of indirect effect among the total effect) will be used as mediation result for visualization. Upon selecting Estimate, the mediation estimates (indirect and total effect) will be used as mediation result for visualization. The default is Proportion.\nEstimate type: Upon selecting Estimate, this checkbox option will show up, providing two choices: IE (indirect effect) and TE (total effect). Users can chose more than one choices to be visualized on the mediation triplot.\n\nProportion type: Upon selecting Proportion, this checkbox option will show up, providing two choices PM(Proportion Mediated) and APM(Adjusted Proportion Mediated): \\[PM=\\frac{IE}{IE+DE}\\] and \\[APM=\\frac{IE}{IE+DE}\\cdot\\frac{|IE+DE|}{|IE|+|DE|}\\]\nThe former represents the conventional way of calculating proportion mediated, without considering the situation when the direct and indirect effect goes into opposite directions. This may lead to a proportion bigger than 1.\nThe latter method represents a novel way to calulate adjusted proportion mediated. The formula use the absolute value of direct and indirect effect to calculate total effect, which limits the proportion mediated to be within 0-1. The directionality of indirect and total effect are also taken into account. Users can chose more than one choices to be visualized on the mediation triplot.\n\nlog(risk): Users can choose whether they want their risk estimates to be presented as beta coefficients or odds ratios. Two options are provided, Yes and No . By selecting Yes, odds ratio will be used. By selecting No, beta coefficient will be used. The default is No."
  },
  {
    "objectID": "workflow.html#triplot-with-mediation",
    "href": "workflow.html#triplot-with-mediation",
    "title": "Workflow",
    "section": "\n5.3 Triplot with mediation",
    "text": "5.3 Triplot with mediation\nThe green box represents visualization outputs. With omics data from step 1 and exposure and outcome data from step 2 uploaded and mediation analysis performed, upon clicking the Refresh plot button, the selected exposures’ correlations, selected outcomes risk associations’ and mediation analysis estimates are co-visualized. The figure can be downloaded by clicking Download mediation triplot."
  },
  {
    "objectID": "workflow.html#mediation-barplots",
    "href": "workflow.html#mediation-barplots",
    "title": "Workflow",
    "section": "\n5.4 Mediation barplots",
    "text": "5.4 Mediation barplots\nWe also provide mediation barplots in Step 4, which focus on visualizing the mediation estimates and directions through barplot, using one exposure, one mediator(principal component) and one outcome. The barplot visualization for conventional and counterfactual mediation analysis are separated. \n\n5.4.1 Visualization settings\nThe orange box represents visualization settings. After mediation analyses are run, Exposure/Mediator/Outcome variables that are involved in the mediation analyses will show up in the options for visualization settings. Users can choose one exposure, one mediator and one outcome to make the barplot.\n\n5.4.2 Conventional/Counterfactual mediation barplot\nThe green box represents visualization outputs. Upon clicking the Refresh plot button, the mediation barplot for the selected exposure, mediator and outcome is shown. The figure can be downloaded by clicking Download conventional/counterfactual mediaiton barplot."
  },
  {
    "objectID": "workflow.html#visualization-settings-4",
    "href": "workflow.html#visualization-settings-4",
    "title": "Workflow",
    "section": "\n6.1 Visualization settings",
    "text": "6.1 Visualization settings\nThe orange box represents visualization settings.\n\n\nPCs to remove: All the selected principal components from step 1 will show up as rows in the heatmap. Users can decide which principal components they want to remove from the heatmap visualizations here.\nShow correlation coefficients/risk estimates/mediation estimates : The users can decide what heatmap they want to be shown. The default is Yes for all options.\nCorrelation(s)/Risk(s) to remove: All the selected exposures and outcomes from step 2 will show up as columns in the heatmap. Users can decide which exposures and outcomes they want to remove from all the heatmap visualizations here.\nMediation estimate type: For the mediation heatmap, users can choose what mediation result (indirect effect, total effect, two types of proportion mediated) they want to show."
  },
  {
    "objectID": "workflow.html#visualizations-3",
    "href": "workflow.html#visualizations-3",
    "title": "Workflow",
    "section": "\n6.2 Visualizations",
    "text": "6.2 Visualizations\nThe green box represents visualization outputs. Upon clicking the Refresh plot button, the heatmaps for correlations (between selected exposures and principal components), risk associations (between selected outcomes and principal components) and mediations (based on the selected exposures, outcomes, principal components and step 4’s completed mediation analysis results) are shown. The figure can be downloaded by clicking Download figure."
  },
  {
    "objectID": "workflow.html#download-processed-data",
    "href": "workflow.html#download-processed-data",
    "title": "Workflow",
    "section": "\n7.1 Download processed data",
    "text": "7.1 Download processed data\nIn the The darkblue box, users can download processed data in csv format. The processed data of Omics, exposures and outcomes, i.e. data after possible variable removal and class change mentioned in 1.1.2 and 1.2.2, can be viewed and downloaded here.\nIf auxilary data or covariate data are uploaded in step 1 and 2, they processed version can be similarly viewed and downloaded here.\nSeparately, the selected exposures, outcomes and principal components as mediator variables that are used in the mediation analysis in step 4 can be viewed and downloaded here."
  },
  {
    "objectID": "workflow.html#download-exposuress-correlations-outcomes-associations-and-mediation-results",
    "href": "workflow.html#download-exposuress-correlations-outcomes-associations-and-mediation-results",
    "title": "Workflow",
    "section": "\n7.2 Download exposures’s correlations, outcomes’ associations and mediation results",
    "text": "7.2 Download exposures’s correlations, outcomes’ associations and mediation results\nFrom the lightblue box, results from correlations, associations and mediation can be viewed and download here.\n\n\nCorrelation matrix are correlation coefficients between exposures and principal components generated from step 2.\np values of correlations are p values of correlations between exposures and principal components generated from step 2.\n\n\nRisk estimates are beta coefficients between the outcome-principal component association generated from step 2. If users want to use odds ratios, they just simply need to calculate the exponential of the data.\np values of risks are p values of risk estimates between outcomes and principal components generated from step 2.\n\n\nmediation estimates are indirect effect, total effect proportion mediatated and adjusted proportion mediated for each combination of exposure, principal component as mediator and outcome generated from step 4.\np values of mediation estimates are p values of indirect effect, total effect proportion mediatated and adjusted proportion mediated for each combination of exposure, principal component as mediator and outcome generated from step 4."
  },
  {
    "objectID": "workflow.html#tpobject",
    "href": "workflow.html#tpobject",
    "title": "Workflow",
    "section": "\n7.3 TPObject",
    "text": "7.3 TPObject\nIn the red box, users can download the TPObject from step 4 in rda format as end product. We refer the list that we use to save information and pass them through the steps as TPObject.\n\n\n\n\n\n\nNote\n\n\n\nIf you are interested, please check out the Tutorial(simple), Tutorial(complex), Use Case. to explore what is contained in the TPObject from each step!"
  },
  {
    "objectID": "workflow.html#show-data",
    "href": "workflow.html#show-data",
    "title": "Workflow",
    "section": "\n7.4 Show data",
    "text": "7.4 Show data\nIn the green box,the intermediate data and the generated results can be viewed. Upon clicking View, the corresponding data will show up here.\n\n\nReference"
  }
]